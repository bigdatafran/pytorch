

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>6. Tema 2 &#8212; Trabajando con PyTorch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'jupyters/Tema 2';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Introducción problemas de clasificación." href="Tema_3_clasificacion.html" />
    <link rel="prev" title="4. Regresión lineal." href="Tema1regresionlineal.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../introduccion.html">
  
  
  
  
  
    <p class="title logo__title">Trabajando con PyTorch</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../introduccion.html">
                    Introducción
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Pycharm</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="OperacionesTensores.html">1. Los tensores en PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="Calcularderivadas.html">2. Introducción a PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="OptimizadoresPyTorch.html">3. Optimizadores en PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tema1regresionlineal.html">4. Regresión lineal.</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">6. Regresión lineal. Continuación</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tema_3_clasificacion.html">7. Problemas de clasificación</a></li>
<li class="toctree-l1"><a class="reference internal" href="capitulo4_clasificacionImagenes.html">8. Introducción clasificación de imágenes.</a></li>


<li class="toctree-l1"><a class="reference internal" href="ModelosPreentrenados.html">11. TorchVision-Modelos preentrenados</a></li>
<li class="toctree-l1"><a class="reference internal" href="Capitulo4bisEspacioFeatures.html">12. Espacio Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="Capitulo5Convoluciones.html">13. Introducción a las convoluciones.</a></li>












<li class="toctree-l1"><a class="reference internal" href="Tema11_NLP.html">26. Lenguaje natural</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Apéndice</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Apendice.html">27. Apéndice</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Índice de términos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">28. Índice de términos</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/jupyters/Tema 2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tema 2</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">6.1. Introducción.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#funciones-de-orden-alto-higher-order">6.2. funciones de orden alto (higher-order).</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-tensordataset-y-dataloader">6.3. Dataset, TensorDataset y DataLoader.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-split">6.4. Random Split.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion">6.5. Evaluación.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorboard">6.6. TensorBoard.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#add-graph">6.7. add_graph.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guardando-y-cargando-modelos">6.8. Guardando y cargando modelos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#utilizando-clases-de-python-para-construir-el-modelo">6.9. Utilizando clases de Python para construir el modelo.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-uso">6.10. Ejemplo de uso.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-uso-regresion-multiple">6.11. Ejemplo de uso regresión múltiple.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estandarizacion-de-los-datos">6.11.1. Estandarización de los datos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apendice">6.12. Apéndice.</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tema-2">
<h1><span class="section-number">6. </span>Tema 2<a class="headerlink" href="#tema-2" title="Permalink to this heading">#</a></h1>
<section id="introduccion">
<h2><span class="section-number">6.1. </span>Introducción.<a class="headerlink" href="#introduccion" title="Permalink to this heading">#</a></h2>
<p>En este tema continuaremos mejorando y optimizando la generación de código que se ha mostrado en el tema anterior. Lo primero que vamos a hacer es cargar una serie de librerías que son las que vamos a necesitar, y el código además lo vamos a guardar para reutilizarlo es códigos posteriores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> librerias/v0.py

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1">#%matplotlib inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting librerias/v0.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i librerias/v0.py
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</section>
<section id="funciones-de-orden-alto-higher-order">
<h2><span class="section-number">6.2. </span>funciones de orden alto (higher-order).<a class="headerlink" href="#funciones-de-orden-alto-higher-order" title="Permalink to this heading">#</a></h2>
<p>Para el desarrollo que queremos hacer posteriormente necesitamos antes introducir una herramienta muy poderosa de Python que consiste en las funciones de alto nivel, o también funciones anidadas, las cuales nos permiten devolver funciones mediante la llamada a otra función.</p>
<p>Veamos el siguiente ejemplo, en el que queremos utilizar la función de exponenciación. Esta función necesita dos parámetros para su ejecución, por un lado estaría el valor de la base y por otro el exponente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">exponentiation_builder</span><span class="p">(</span><span class="n">exponent</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">skeleton_exponentiation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="n">exponent</span>
    <span class="k">return</span> <span class="n">skeleton_exponentiation</span>
</pre></div>
</div>
</div>
</div>
<p>Como puede verse en ese código tenemos definido una jerarquía de funciones, de manera que si llamamos a <em>exponentiation_builder</em> lo que nos devuelve es otra función pero ya con un determinado exponente. Veamoslo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expo</span> <span class="o">=</span> <span class="n">exponentiation_builder</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">expo</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.exponentiation_builder.&lt;locals&gt;.skeleton_exponentiation(x)&gt;
</pre></div>
</div>
</div>
</div>
<p>Como vemos ahora nos está devolviendo una referencia a otra función y se puede utilizar como si de una función se tratara.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expo</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16
</pre></div>
</div>
</div>
</div>
<p>Realmente con todo este código lo que hemos hecho es calcular <span class="math notranslate nohighlight">\(2^4\)</span>. Este tipo de funciones anidadas nos va a servir mucho para poder modificar con funciones aspectos tales como la función de coste a utilizar, el optimizador a emplear, etc.</p>
<p>Entonces utilizando esta idea, procedemos a definir dos funciones anidadas que nos permitirán modificar diferentes operadores cuando procedemos a hacer el entrenamiento de un modelo. Estas funciones son las siguientes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> funciones/make_train_step_fn.py

<span class="k">def</span> <span class="nf">make_train_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Los parámetros de entrada son un modelo, una función de pérdida y un optimizador</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Builds function that performs a step in the train loop</span>
    <span class="k">def</span> <span class="nf">perform_train_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1">## X son los datos del train (var independiente)</span>
        <span class="c1">## y los valores esperados (var. dependiente)</span>
        <span class="c1"># Sets model to TRAIN mode</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Step 2 - Computes the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># Step 3 - Computes gradients for both &quot;a&quot; and &quot;b&quot; parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Step 4 - Updates parameters using gradients and the learning rate</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="c1"># Devuelve los valores de la función de pérdida</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Returns the function that will be called inside the train loop</span>
    <span class="k">return</span> <span class="n">perform_train_step_fn</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting funciones/make_train_step_fn.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/make_train_step_fn.py
</pre></div>
</div>
</div>
</div>
<p>Con las funciones indicadas en el bloque anterior, introducimos una gran flexibilidad al modelo, ya que mediante la función más externa podemos pasar el modelo, la función de pérdida y el optimizador, para después con la salida que no de pasarle los datos de la variable independiente y los valores previsto. Con todo ello ya podríamos entrenar nuestro modelo.</p>
<p>Vamos a ver ahora cómo lo podríamos utilizar de una forma práctica.</p>
<p>Primero ejecutamos el fichero de preparación de los datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> data_preparation/v0_0.py

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">true_b</span><span class="o">=</span><span class="mi">1</span> <span class="c1">#Valor verdadero de B</span>
<span class="n">true_w</span><span class="o">=</span><span class="mi">2</span> <span class="c1">#Valor verdadero de w</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Generamos números aleatorios para x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># generamos la variable de ruido</span>
<span class="c1"># randn para generar datos de una distribución normal</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># generamos los datos de la variable dependiente</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">true_b</span> <span class="o">+</span> <span class="n">true_w</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="c1"># Shuffles de los índices</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="c1"># 80 por ciento para train</span>
<span class="n">train_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="mf">.8</span><span class="p">)]</span>
<span class="c1"># El resto para test</span>
<span class="n">val_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="mf">.8</span><span class="p">):]</span>
<span class="c1"># Generamos el conjunto de datos de train y de test</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting data_preparation/v0_0.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="o">%</span><span class="k">run</span> -i data_preparation/v0_0.py
<span class="o">%</span><span class="k">run</span> -i data_preparation/v0.py
</pre></div>
</div>
</div>
</div>
<p>A continuación creamos la configuración del modelo y al final del código utilizamos la función <em>make_train_step_fn</em> creada anteriormente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_configuration/v1.py

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

<span class="c1"># Sets learning rate - this is &quot;eta&quot; ~ the &quot;n&quot; like Greek letter</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Now we can create a model and send it at once to the device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Defines a SGD optimizer to update the parameters (now retrieved directly from the model)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a MSE loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="c1"># Creates the train_step function for our model, loss function and optimizer</span>
<span class="c1">### OJO aquí está la llamada a la función anidada creada anteriormente</span>
<span class="n">train_step_fn</span> <span class="o">=</span> <span class="n">make_train_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_configuration/v1.py
</pre></div>
</div>
</div>
</div>
<p>El código anterior se ejecutaría de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_configuration/v1.py
</pre></div>
</div>
</div>
</div>
<p>Veamos qué tiene la variables <em>train_step_fn</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_step_fn</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.make_train_step_fn.&lt;locals&gt;.perform_train_step_fn(x, y)&gt;
</pre></div>
</div>
</div>
</div>
<p>Entonces teniendo en cuenta todo estos, ahora ya podemos crear nuestro módulo de entrenamiento, y además podemos ir recogiendo los valores de la función de pérdida en una lista para por ejemplo ir viendo cómo va su evolución.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_training/v1.py

<span class="c1"># Defines number of epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each epoch...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># Performs one train step and returns the corresponding loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">train_step_fn</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_training/v1.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v1.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># vemos los valores de model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9690]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0235], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
<p>Observar que en los pasos anteriores, hemos separado los tres pasos que aconsejamos dar en el capítulo anterior para construir estos modelos.</p>
<ul class="simple">
<li><p>Preparación de los datos.</p></li>
<li><p>Configuración del modelo.</p></li>
<li><p>Entrenamiento del modelo.</p></li>
</ul>
</section>
<section id="dataset-tensordataset-y-dataloader">
<span id="dataset"></span><h2><span class="section-number">6.3. </span>Dataset, TensorDataset y DataLoader.<a class="headerlink" href="#dataset-tensordataset-y-dataloader" title="Permalink to this heading">#</a></h2>
<p id="index-0">En apartados anteriores hemos trabajado con datos almacenados como dataframe, numpy array o como tensores, pero Pytorch también dispone de herramientas para adaptar de una forma mejor los datos para posteriormente poder ser tratados de una forma más eficiente, sobre todo si se trata de grandes volúmenes de datos.  En este apartado vamos a exponer las posibilidades que nos ofrece Pytorch para ello.</p>
<p>En Pytorch, un dataset está representado por una clase de Python que hereda de la clase <em>Dataset</em>. Se puede pensar en este tipo de estructura de datos como una lista de tuplas y cada elemento de esa lista corresponde a un punto, en el <em>formato (features, label)</em>.</p>
<p>Los métodos más fundamentales de esta clase son:</p>
<ul class="simple">
<li><p><strong><strong>init</strong>(self)</strong>: Es el método de inicialización de una clase Python y toma los argumentos necesarios para construir una lista de tuplas. puede ser el nombre de un archivo CSV que será cargado y procesado; puede ser dos tensores, uno para las características otro para las etiquetas; o cualquier otra cosa, dependiendo de la tarea que se quiera realizar.</p></li>
<li><p><strong><strong>get_item</strong>(self,index)</strong>. Con este método el dataset puede ser indexado y poder trabajar como una lista de tuplas (features, labels). <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class" target="_blank"> En este enlace se puede ver un ejemplo </a>.</p></li>
<li><p><strong><strong>len</strong>(self)</strong>. Simplemente debería devolver el tamaño de todo el conjunto de datos, de modo que, siempre que se muestree, su indexación se limite al tamaño real.</p></li>
</ul>
<p>Con estas ideas, a continuación procedemos a crear una clase de Python que se encargara de crear un dataset que va a tomar dos tensores como argumentos: Los datos de la x y los datos de la y.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x_tensor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y_tensor</span>
        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span> 
        <span class="c1"># Devuelve un par (feature, label) como se ha dicho antes</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Wait, is this a CPU tensor now? Why? Where is .to(device)?</span>
<span class="n">x_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([0.7713]), tensor([2.4745]))
</pre></div>
</div>
</div>
</div>
<p>No obstante todo lo anterior, y con el fin de facilitar aún más la tarea, Pytorch tiene una clase denominada <em>TensorDataset</em> que no requiere una construcción previa de ningún tipo de clase ad hoc de Python. La forma de utilizar esta clase es la que a continuación se muestra.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([0.7713]), tensor([2.4745]))
</pre></div>
</div>
</div>
</div>
<p>Todo lo hecho hasta ahora está muy bien,pero hay que tener en cuenta que hemos utilizado <strong>todos los datos</strong> de entrenamiento en cada de entrenamiento. Ha sido el descenso de gradiente por lotes (batch gradient descent) todo el tiempo.</p>
<p>Esto está bien para y no da problemas para un conjunto de datos ridículamente pequeño, con el que se trabajado hasta ahora, pero si queremos ir en serio sobre todo esto y tenemos una gran cantidad de datos, debemos usar el descenso de gradiente en mini lotes. Por lo tanto, necesitamos mini-lotes (mini-batch gradient descent). Por lo tanto, tenemos que cortar nuestro conjunto de datos en consecuencia con los datos que tenemos y la capacidad de nuestro equipo.</p>
<p>Realmente lo que necesitamos es que nuestro cargador se comporte como un iterador, por lo que podemos hacer un bucle sobre él y obtener un mini-lote diferente en cada pasada del iterador. Lo más normal es utilizar en cada iteración conjuntos de datos (mini-batch) que ocupen un múltiplo de 2 : 16,32,64 o 128. Para conseguir esto utilizamos la clase <em>DataLoader</em>, y a continuación mostramos un ejemplo de uso de la misma.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Para ver el contenido, vamos a ejecutar la siguiente instrucción.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[tensor([[0.2809],
         [0.3253],
         [0.1560],
         [0.5924],
         [0.0651],
         [0.8872],
         [0.4938],
         [0.0055],
         [0.1409],
         [0.0885],
         [0.1849],
         [0.7290],
         [0.8662],
         [0.3117],
         [0.6842],
         [0.1987]]),
 tensor([[1.5846],
         [1.8057],
         [1.2901],
         [2.1687],
         [1.1559],
         [2.8708],
         [1.9060],
         [1.0632],
         [1.1211],
         [1.0708],
         [1.5888],
         [2.4927],
         [2.6805],
         [1.7637],
         [2.3492],
         [1.2654]])]
</pre></div>
</div>
</div>
</div>
<p>Como vemos devuelve una lista conteniendo dos tensores, el primer tensor conteniendo las <em>features</em> y el segundo los <em>labels</em>.</p>
<p>Como puede verse, para trabajar con este tipo de carga de datos hay que manejar los <a href="https://realpython.com/python-for-loop/#iterables" href="_blank"> iterables </a> y los <a href="https://realpython.com/python-for-loop/#iterators" target="_blank"> iterartors </a> de Python.</p>
<p>También se puede ver su contenido utilizando <em>enumerate</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.7852],
        [0.8022],
        [0.6075],
        [0.1997],
        [0.3309],
        [0.6376],
        [0.4722],
        [0.2809],
        [0.4938],
        [0.5427],
        [0.1560],
        [0.1987],
        [0.3745],
        [0.0885],
        [0.7320],
        [0.8872]])
</pre></div>
</div>
</div>
</div>
<p>Entonces adaptando todos estos elementos para el ejemplo que estamos construyendo, podríamos definir el siguiente código</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> data_preparation/v1.py

<span class="c1"># Our data was in Numpy arrays, but we need to transform them into PyTorch&#39;s Tensors</span>
<span class="n">x_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Builds Dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>

<span class="c1"># Builds DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting data_preparation/v1.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i data_preparation/v1.py
</pre></div>
</div>
</div>
</div>
<p>Una vez hecho esto necesitamos modificar el código del apartado de código de entrenamiento para adaptarlo a la entrada de datos de tipo mini-batch que antes ya se ha presentado. Entonces primero cargamos la parte de configuración (recordemos que aquí lo que hacemos es definir la función de coste, el modelo y el optimizador).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_configuration/v1.py
</pre></div>
</div>
</div>
</div>
<p>Y ahora ya adoptamos la parte de entrenamiento para que pueda operar con la entrada de datos en formato mini-batch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_training/v2.py

<span class="c1"># Defines number of epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each epoch...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># inner loop</span>
    <span class="n">mini_batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># the dataset &quot;lives&quot; in the CPU, so do our mini-batches</span>
        <span class="c1"># therefore, we need to send those mini-batches to the</span>
        <span class="c1"># device where the model &quot;lives&quot;</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Performs one train step and returns the corresponding loss </span>
        <span class="c1"># for this mini-batch</span>
        <span class="c1">### La función train_step_fn se ha definido antes dentro de la jerarquía de funciones</span>
        <span class="n">mini_batch_loss</span> <span class="o">=</span> <span class="n">train_step_fn</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> 
        <span class="n">mini_batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mini_batch_loss</span><span class="p">)</span>

    <span class="c1"># Computes average loss over all mini-batches - that&#39;s the epoch loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mini_batch_losses</span><span class="p">)</span>
    
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_training/v2.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v2.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9696]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0243], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
<p>Recapitulemos todos los códigos guardados hasta la fecha y pongámoslo en marcha. Lo hacemos en la siguiente celda</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/make_train_step_fn.py
<span class="o">%</span><span class="k">run</span> -i data_preparation/v0_0.py
<span class="o">%</span><span class="k">run</span> -i librerias/v0.py
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">run</span> -i data_preparation/v1.py
<span class="o">%</span><span class="k">run</span> -i model_configuration/v1.py
<span class="o">%</span><span class="k">run</span> -i model_training/v2.py
</pre></div>
</div>
</div>
</div>
<p>Podemos observar que el entrenamiento del modelo ahora emplea más tiempo que antes, el motivo no es otro que el bucle Mini-Batch que ahora hacemos ralentiza el proceso, ya que en total debemos hacer ahora un total de 5 ciclos (80/16=5).</p>
<p>Otra modulación que podemos hacer en este programa es la etapa del Mini-Bach. Si tenemos en cuenta que esta etapa está definida por los siguientes elementos:</p>
<ul class="simple">
<li><p>El <strong>device</strong> al cual se envían los datos.</p></li>
<li><p>Un <strong>data loader</strong> donde se definen los Mini-Batches</p></li>
<li><p>Una <em>función step</em> que devuelve los correspondientes <em>loss</em>.</p></li>
</ul>
<p>Podemos integrar todos los componentes dentro de una función que tenga por parámetros los elementos antes indicados y de esta manera podremos encapsular el código de una forma adecuada. Lo hacemos a continuación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> funciones/mini_batch.py

<span class="k">def</span> <span class="nf">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">step_fn</span><span class="p">):</span>
    <span class="n">mini_batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">mini_batch_loss</span> <span class="o">=</span> <span class="n">step_fn</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">mini_batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mini_batch_loss</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mini_batch_losses</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting funciones/mini_batch.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/mini_batch.py
</pre></div>
</div>
</div>
</div>
<p>Entonces con este cambio el modelo de entrenamiento quedaría de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_training/v3.py

<span class="c1"># Defines number of epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># inner loop</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">train_step_fn</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_training/v3.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v3.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checks model&#39;s parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9696]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0260], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
<p>Ahora los módulos que deberiamos ejecutar para obtener todos los resultados vistos hasta ahora serían los siguientes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/make_train_step_fn.py
<span class="o">%</span><span class="k">run</span> -i data_preparation/v0_0.py
<span class="o">%</span><span class="k">run</span> -i librerias/v0.py
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">run</span> -i data_preparation/v1.py
<span class="o">%</span><span class="k">run</span> -i model_configuration/v1.py
<span class="o">%</span><span class="k">run</span> -i funciones/mini_batch.py
<span class="o">%</span><span class="k">run</span> -i model_training/v3.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checks model&#39;s parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9684]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0219], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-split">
<h2><span class="section-number">6.4. </span>Random Split.<a class="headerlink" href="#random-split" title="Permalink to this heading">#</a></h2>
<p id="index-1">Meadiante <em>Random Split</em> que nos proporciona pycharm, podemos hacer una división de los datos entre los que sirven de entrenamiento y los de validación, sin tener que utilizar herramientas de otras librerías. La forma de hacerlo la podemos ver en el código siguiente:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> data_preparation/v2.py

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>

<span class="c1"># Builds tensors from numpy arrays BEFORE split</span>
<span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Builds dataset containing ALL data points</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>

<span class="c1"># Performs the split</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="mf">.8</span>
<span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_total</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">)</span>
<span class="n">n_val</span> <span class="o">=</span> <span class="n">n_total</span> <span class="o">-</span> <span class="n">n_train</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_val</span><span class="p">])</span>

<span class="c1"># Builds a loader of each set</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting data_preparation/v2.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i data_preparation/v2.py
</pre></div>
</div>
</div>
</div>
</section>
<section id="evaluacion">
<h2><span class="section-number">6.5. </span>Evaluación.<a class="headerlink" href="#evaluacion" title="Permalink to this heading">#</a></h2>
<p>Una vez configurado el modelo, es la hora de hacer su evaluación con datos que no se han utilizado en su creación. En la evaluación debemos calcular para los datos de evaluación el valor que predice el modelo y compararlo con el valor real y de ahí poder sacar los indicadores de evaluación correspondientes.</p>
<p>Para hacer las evaluaciones del modelo debemos utilizar el código <em>model.eval()</em> con la finalidad de que no se calculen los gradientes, o que los mimos sean igual a cero con lo cual conseguiremos que los pesos o parámetros del modelo sean los mismos que los que ya se han calculado durante la etapa de entrenamiento del mismo.</p>
<p>Definimos a continuación un función de ayuda para la evaluación del modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> funciones/make_val_step_fn.py

<span class="k">def</span> <span class="nf">make_val_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
    <span class="c1"># Builds function that performs a step in the validation loop</span>
    <span class="k">def</span> <span class="nf">perform_val_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># Sets model to EVAL mode</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1">### OJO aqui para indica que estamos en la evaluación</span>
        
        <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Step 2 - Computes the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># There is no need to compute Steps 3 and 4, since we don&#39;t update parameters during evaluation</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">perform_val_step_fn</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting funciones/make_val_step_fn.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/make_val_step_fn.py
</pre></div>
</div>
</div>
</div>
<p>Y ahora procedemos a modificar el código de nuestro modelo de configuración de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_configuration/v2.py

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

<span class="c1"># Sets learning rate - this is &quot;eta&quot; ~ the &quot;n&quot; like Greek letter</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Now we can create a model and send it at once to the device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Defines a SGD optimizer to update the parameters (now retrieved directly from the model)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a MSE loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="c1"># Creates the train_step function for our model, loss function and optimizer</span>
<span class="n">train_step_fn</span> <span class="o">=</span> <span class="n">make_train_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># Creates the val_step function for our model and loss function</span>
<span class="n">val_step_fn</span> <span class="o">=</span> <span class="n">make_val_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_configuration/v2.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_configuration/v2.py
</pre></div>
</div>
</div>
</div>
<p>Ahora ya podemos implementar nuestro código de entrenamiento, teniendo también en cuenta el proceso de validación del modelo. El código que utilizaremos sería el siguiente</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_training/v4.py

<span class="c1"># Defines number of epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># inner loop</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">train_step_fn</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="c1"># Paso de validación VALIDATION (lo incorporo ahora)</span>
    <span class="c1"># no gradients in validation!</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1">#!!!! Ojo muy importante para no calcular los gradientes</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">val_step_fn</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_training/v4.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v4.py
</pre></div>
</div>
</div>
</div>
<p>Muy importante en el código anterior. Cuando introducimos el entorno <em>with torch.no_grad()</em> lo que hacemos es no computar los gradientes y por lo tanto los parámetros se mantendrán en los calculados por el modelo en la etapa del entrenamiento.</p>
<p>Después de hacer todos estos cambios, nuestra etapa actual en la que nos llegamos, se reproduce de la siguiente manera:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i funciones/make_train_step_fn.py
<span class="o">%</span><span class="k">run</span> -i funciones/make_val_step_fn.py
<span class="o">%</span><span class="k">run</span> -i data_preparation/v0_0.py
<span class="o">%</span><span class="k">run</span> -i librerias/v0.py
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">run</span> -i data_preparation/v2.py
<span class="o">%</span><span class="k">run</span> -i model_configuration/v2.py
<span class="o">%</span><span class="k">run</span> -i funciones/mini_batch.py
<span class="o">%</span><span class="k">run</span> -i model_training/v4.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checks model&#39;s parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9438]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0287], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
<p>Podemos ahora comparar los valores de Loss que se han obtenido tanto para los datos de entrenamiento como de evaluación</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_losses</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/99058e210e28abd533927bc65d791f8ae5c7ea161e8ce2747c69ca1739ce009d.png" src="../_images/99058e210e28abd533927bc65d791f8ae5c7ea161e8ce2747c69ca1739ce009d.png" />
</div>
</div>
</section>
<section id="tensorboard">
<h2><span class="section-number">6.6. </span>TensorBoard.<a class="headerlink" href="#tensorboard" title="Permalink to this heading">#</a></h2>
<p id="index-2">TensorBoard es un magnifica herramienta a utilizar dentro de deeplearning. En este apartartaddo vamos a manejarla desde dos puntos de vista. Uno en el entorno de Jupyter notebook y otro de forma independiente.</p>
<p>Comenzamos a utilizarla desde Jupyter Notebook, para ello necesitaremos una serie de comandos mágicos, que a continuación se procede a explicar.</p>
<p>Primero incluimos la extensión para jupyter</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the TensorBoard notebook extension</span>
<span class="o">%</span><span class="k">load_ext</span> tensorboard
</pre></div>
</div>
</div>
</div>
<p>Y ahora ya podremos usar tensorboard de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir runs --port=6006
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reusing TensorBoard on port 6006 (pid 10024), started 0:48:07 ago. (Use &#39;!kill 10024&#39; to kill it.)
</pre></div>
</div>
<div class="output text_html">
      <iframe id="tensorboard-frame-283fc73c6370341d" width="100%" height="800" frameborder="0">
      </iframe>
      <script>
        (function() {
          const frame = document.getElementById("tensorboard-frame-283fc73c6370341d");
          const url = new URL("/", window.location);
          const port = 6006;
          if (port) {
            url.port = port;
          }
          frame.src = url;
        })();
      </script>
    </div></div>
</div>
<p>De momento no nos facilita ningún tipo de información ya que no hemos enviado ningún datos a la carpeta <em>runs</em>, posteriormente cuando lo hagamos nos ofrecerá diversas opciones muy interesantes para el trabajo con tensores.</p>
<p>También lo podemos activar de forma separada, para ello lo que hay que ejecutar en una linea de comandos es la instrucción: <em>tensorboard –logdir runs</em> y entonces en la pantalla de comandos nos aparecerán los siguientes mensajes:</p>
<p><img alt="Tensor Board" src="../_images/tensorBoard.PNG" /></p>
<p>Ahora nos debemos ir a un navegador web e introducir en la barra de direcciones <em><a class="reference external" href="http://localhost:6006/">http://localhost:6006/</a></em> para ver en dicho navegador una imagen similar a la que se nos ha presentado anteriormente en una celda de este jupyter.</p>
<p id="index-3">Recordemos que le hemos indicado a tensorFlow que todos nuestros logs para este trabajo se encuentran en la carpeta denominada <em>runs</em>. Entonces debemos comenzar por por la creación de un <a href="https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter" target="_blank"> <em>SummaryWriter</em> </a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.tensorboard.writer</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;runs/test&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>SummaryWriter implementa diferentes métodos que permiten enviar información a dashboart</p>
<p><img alt="metodos tensorFlow" src="../_images/metodoTF.PNG" /></p>
<p>También implementa otros dos métodos para la escritura efectiva de datos en disco</p>
<ul class="simple">
<li><p>flush</p></li>
<li><p>close</p></li>
</ul>
<p>Utilizaremos los dos primeros métodos (add_graph y add_scalars) para enviar el gráfico de nuestro modelo (aunque no es lo mismo que el gráfico de que dibujamos con make_dot…) y, por supuesto, los dos escalares: training y validación losses.</p>
</section>
<section id="add-graph">
<h2><span class="section-number">6.7. </span>add_graph.<a class="headerlink" href="#add-graph" title="Permalink to this heading">#</a></h2>
<p>Añadimos información para tensorboard de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>example_kwarg_inputs should be a dict
Error occurs, No graph saved
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">51</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="nn">File D:\MisTrabajos\Pytorch\pytorch\lib\site-packages\torch\utils\tensorboard\writer.py:841,</span> in <span class="ni">SummaryWriter.add_graph</span><span class="nt">(self, model, input_to_model, verbose, use_strict_trace)</span>
<span class="g g-Whitespace">    </span><span class="mi">837</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;tensorboard.logging.add_graph&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">838</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;forward&quot;</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">839</span>     <span class="c1"># A valid PyTorch model should have a &#39;forward&#39; method</span>
<span class="g g-Whitespace">    </span><span class="mi">840</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">841</span>         <span class="n">graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_to_model</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">use_strict_trace</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">842</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">843</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">844</span>     <span class="c1"># Caffe2 models do not have the &#39;forward&#39; method</span>
<span class="g g-Whitespace">    </span><span class="mi">845</span>     <span class="kn">from</span> <span class="nn">caffe2.proto</span> <span class="kn">import</span> <span class="n">caffe2_pb2</span>

<span class="nn">File D:\MisTrabajos\Pytorch\pytorch\lib\site-packages\torch\utils\tensorboard\_pytorch_graph.py:343,</span> in <span class="ni">graph</span><span class="nt">(model, args, verbose, use_strict_trace)</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span>         <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">342</span>         <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error occurs, No graph saved&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">343</span>         <span class="k">raise</span> <span class="n">e</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>     <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

<span class="nn">File D:\MisTrabajos\Pytorch\pytorch\lib\site-packages\torch\utils\tensorboard\_pytorch_graph.py:337,</span> in <span class="ni">graph</span><span class="nt">(model, args, verbose, use_strict_trace)</span>
<span class="g g-Whitespace">    </span><span class="mi">335</span> <span class="k">with</span> <span class="n">_set_model_to_eval</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">336</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">337</span>         <span class="n">trace</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">use_strict_trace</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">338</span>         <span class="n">graph</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">graph</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span>         <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_inline</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>

<span class="nn">File D:\MisTrabajos\Pytorch\pytorch\lib\site-packages\torch\jit\_trace.py:793,</span> in <span class="ni">trace</span><span class="nt">(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">791</span>             <span class="n">example_inputs</span> <span class="o">=</span> <span class="n">example_kwarg_inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span>         <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">793</span>             <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;example_kwarg_inputs should be a dict&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span>     <span class="k">return</span> <span class="n">trace_module</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">795</span>         <span class="n">func</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">796</span>         <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="n">example_inputs</span><span class="p">},</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">805</span>         <span class="n">_store_inputs</span><span class="o">=</span><span class="n">_store_inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">806</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">807</span> <span class="k">if</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">808</span>     <span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s2">&quot;__self__&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">809</span>     <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">810</span>     <span class="ow">and</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;forward&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">811</span> <span class="p">):</span>

<span class="ne">RuntimeError</span>: example_kwarg_inputs should be a dict
</pre></div>
</div>
</div>
</div>
<p>Como vemos nos genera un error, debido a que necesitamos enviar algún input junto con nuestro modelo. Lo solucionamos de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fetching a tuple of feature (dummy_x) and label (dummy_y)</span>
<span class="n">dummy_x</span><span class="p">,</span> <span class="n">dummy_y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="c1"># Since our model was sent to device, we need to do the same</span>
<span class="c1"># with the data.</span>
<span class="c1"># Even here, both model and data need to be on the same device!</span>
<span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">},</span> <span class="n">epoch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Como no me sale lo dejo aquí el tema de tensorboard. Sin embargo sigo actualizando el código</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i data_preparation/v2.py
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_configuration/v3.py

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

<span class="c1"># Sets learning rate - this is &quot;eta&quot; ~ the &quot;n&quot; like Greek letter</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Now we can create a model and send it at once to the device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Defines a SGD optimizer to update the parameters (now retrieved directly from the model)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a MSE loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

<span class="c1"># Creates the train_step function for our model, loss function and optimizer</span>
<span class="n">train_step_fn</span> <span class="o">=</span> <span class="n">make_train_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># Creates the val_step function for our model and loss function</span>
<span class="n">val_step_fn</span> <span class="o">=</span> <span class="n">make_val_step_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>

<span class="c1"># Creates a Summary Writer to interface with TensorBoard</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">&#39;runs/simple_linear_regression&#39;</span><span class="p">)</span>

<span class="c1"># Fetches a single mini-batch so we can use add_graph</span>
<span class="n">x_sample</span><span class="p">,</span> <span class="n">y_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_sample</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_configuration/v3.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_configuration/v3.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_training/v5.py

<span class="c1"># Defines number of epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># inner loop</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">train_step_fn</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="c1"># VALIDATION</span>
    <span class="c1"># no gradients in validation!</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">mini_batch</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">val_step_fn</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    
    <span class="c1"># Records both losses for each epoch under the main tag &quot;loss&quot;</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">main_tag</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                       <span class="n">tag_scalar_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">},</span>
                       <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

<span class="c1"># Closes the writer</span>
<span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting model_training/v5.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v5.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Checks model&#39;s parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;, tensor([[1.9432]], device=&#39;cuda:0&#39;)), (&#39;0.bias&#39;, tensor([1.0263], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
</section>
<section id="guardando-y-cargando-modelos">
<h2><span class="section-number">6.8. </span>Guardando y cargando modelos.<a class="headerlink" href="#guardando-y-cargando-modelos" title="Permalink to this heading">#</a></h2>
<p>Vamos a proceder ahora a guardar nuestro modelo en un fichero de disco duro denominado <em>model_checkpoint.pth</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">n_epochs</span><span class="p">,</span>
              <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
              <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
              <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span>
              <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">}</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="s1">&#39;model_checkpoint.pth&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Entonces, si arrancamos de nuevo lo que necesitamos es cargar los códigos de preparación y configuración</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i data_preparation/v2.py
<span class="o">%</span><span class="k">run</span> -i model_configuration/v3.py
</pre></div>
</div>
</div>
</div>
<p>VEamos que aquí el modelo no está entrenado</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora lo que hacemos es cargar los datos que anteriormente hemos guardado</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;model_checkpoint.pth&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>

<span class="n">saved_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
<span class="n">saved_losses</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">saved_val_losses</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># always use TRAIN for resuming training</span>
</pre></div>
</div>
</div>
</div>
<p>Veamos ahora cuales son los datos del modelo</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Como podemos obsrvar ahora el modelo si ha cargado adecuadamente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_training/v5.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="utilizando-clases-de-python-para-construir-el-modelo">
<h2><span class="section-number">6.9. </span>Utilizando clases de Python para construir el modelo.<a class="headerlink" href="#utilizando-clases-de-python-para-construir-el-modelo" title="Permalink to this heading">#</a></h2>
<p>En lo que sigue, vamos a utilizar la potencia de las clases de Python para integrar todo el código anterior en una clase y así hacer mucho más eficiente el código desarrollado hasta el momento.</p>
<p>Comenzamos importando los módulos necesarios</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>comenzamos definiendo la clase</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># A completely empty (and useless) class</span>
<span class="k">class</span> <span class="nc">StepByStep</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
<p>Comenzamos la clase con el constructor de la misma (<strong>init</strong>). Construimos un método denominado <em>to</em> que servirá para enviar los objetos a la GPU si se dispone de la misma</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StepByStep</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="c1"># Here we define the attributes of our class</span>
        
        <span class="c1"># We start by storing the arguments as attributes </span>
        <span class="c1"># to use them later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
        <span class="c1"># Let&#39;s send the model to the specified device right away</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># These attributes are defined here, but since they are</span>
        <span class="c1"># not available at the moment of creation, we keep them None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># These attributes are going to be computed internally</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>        

        <span class="c1"># Creates the train_step function for our model, </span>
        <span class="c1"># loss function and optimizer</span>
        <span class="c1"># Note: there are NO ARGS there! It makes use of the class</span>
        <span class="c1"># attributes directly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_step</span><span class="p">()</span>
        <span class="c1"># Creates the val_step function for our model and loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_val_step</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="c1"># This method allows the user to specify a different device</span>
        <span class="c1"># It sets the corresponding attribute (to be used later in</span>
        <span class="c1"># the mini-batches) and sends the model to the device</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t send it to </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">, sending it to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> instead.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            
    <span class="k">def</span> <span class="nf">set_loaders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># This method allows the user to define which train_loader </span>
        <span class="c1"># (and val_loader, optionally) to use</span>
        <span class="c1"># Both loaders are then assigned to attributes of the class</span>
        <span class="c1"># So they can be referred to later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>

    <span class="k">def</span> <span class="nf">set_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;runs&#39;</span><span class="p">):</span>
        <span class="c1"># This method allows the user to create a SummaryWriter to </span>
        <span class="c1"># interface with TensorBoard</span>
        <span class="n">suffix</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">%H%M%S&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_make_train_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># This method does not need ARGS... it can refer to</span>
        <span class="c1"># the attributes: self.model, self.loss_fn and self.optimizer</span>

        <span class="c1"># Builds function that performs a step in the train loop</span>
        <span class="k">def</span> <span class="nf">perform_train_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to TRAIN mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># Step 3 - Computes gradients for both &quot;b&quot; and &quot;w&quot; parameters</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c1"># Step 4 - Updates parameters using gradients and the</span>
            <span class="c1"># learning rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Returns the loss</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Returns the function that will be called inside the train loop</span>
        <span class="k">return</span> <span class="n">perform_train_step_fn</span>

    <span class="k">def</span> <span class="nf">_make_val_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Builds function that performs a step in the validation loop</span>
        <span class="k">def</span> <span class="nf">perform_val_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to EVAL mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># There is no need to compute Steps 3 and 4, </span>
            <span class="c1"># since we don&#39;t update parameters during evaluation</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">perform_val_step_fn</span>
</pre></div>
</div>
</div>
</div>
<p>Al final el código que queda es el siguiente:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">StepByStep</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="c1"># Here we define the attributes of our class</span>
        
        <span class="c1"># We start by storing the arguments as attributes </span>
        <span class="c1"># to use them later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
        <span class="c1"># Let&#39;s send the model to the specified device right away</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># These attributes are defined here, but since they are</span>
        <span class="c1"># not informed at the moment of creation, we keep them None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># These attributes are going to be computed internally</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Creates the train_step function for our model, </span>
        <span class="c1"># loss function and optimizer</span>
        <span class="c1"># Note: there are NO ARGS there! It makes use of the class</span>
        <span class="c1"># attributes directly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_step_fn</span><span class="p">()</span>
        <span class="c1"># Creates the val_step function for our model and loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_val_step_fn</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="c1"># This method allows the user to specify a different device</span>
        <span class="c1"># It sets the corresponding attribute (to be used later in</span>
        <span class="c1"># the mini-batches) and sends the model to the device</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Couldn&#39;t send it to </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">, sending it to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> instead.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_loaders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># This method allows the user to define which train_loader (and val_loader, optionally) to use</span>
        <span class="c1"># Both loaders are then assigned to attributes of the class</span>
        <span class="c1"># So they can be referred to later</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>

    <span class="k">def</span> <span class="nf">set_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">&#39;runs&#39;</span><span class="p">):</span>
        <span class="c1"># This method allows the user to define a SummaryWriter to interface with TensorBoard</span>
        <span class="n">suffix</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">%H%M%S&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">suffix</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_train_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># This method does not need ARGS... it can refer to</span>
        <span class="c1"># the attributes: self.model, self.loss_fn and self.optimizer</span>
        
        <span class="c1"># Builds function that performs a step in the train loop</span>
        <span class="k">def</span> <span class="nf">perform_train_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to TRAIN mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># Step 3 - Computes gradients for both &quot;a&quot; and &quot;b&quot; parameters</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c1"># Step 4 - Updates parameters using gradients and the learning rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Returns the loss</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Returns the function that will be called inside the train loop</span>
        <span class="k">return</span> <span class="n">perform_train_step_fn</span>
    
    <span class="k">def</span> <span class="nf">_make_val_step_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Builds function that performs a step in the validation loop</span>
        <span class="k">def</span> <span class="nf">perform_val_step_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Sets model to EVAL mode</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

            <span class="c1"># Step 1 - Computes our model&#39;s predicted output - forward pass</span>
            <span class="n">yhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Step 2 - Computes the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># There is no need to compute Steps 3 and 4, </span>
            <span class="c1"># since we don&#39;t update parameters during evaluation</span>
            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">perform_val_step_fn</span>
            
    <span class="k">def</span> <span class="nf">_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># The mini-batch can be used with both loaders</span>
        <span class="c1"># The argument `validation`defines which loader and </span>
        <span class="c1"># corresponding step function is going to be used</span>
        <span class="k">if</span> <span class="n">validation</span><span class="p">:</span>
            <span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span>
            <span class="n">step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_step_fn</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span>
            <span class="n">step_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step_fn</span>

        <span class="k">if</span> <span class="n">data_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
            
        <span class="c1"># Once the data loader and step function, this is the </span>
        <span class="c1"># same mini-batch loop we had before</span>
        <span class="n">mini_batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">mini_batch_loss</span> <span class="o">=</span> <span class="n">step_fn</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">mini_batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mini_batch_loss</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mini_batch_losses</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>    
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
        <span class="c1"># To ensure reproducibility of the training process</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
            <span class="c1"># Keeps track of the numbers of epochs</span>
            <span class="c1"># by updating the corresponding attribute</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># inner loop</span>
            <span class="c1"># Performs training using mini-batches</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mini_batch</span><span class="p">(</span><span class="n">validation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># VALIDATION</span>
            <span class="c1"># no gradients in validation!</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># Performs evaluation using mini-batches</span>
                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mini_batch</span><span class="p">(</span><span class="n">validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

            <span class="c1"># If a SummaryWriter has been set...</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
                <span class="n">scalars</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;training&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">val_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">scalars</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;validation&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">})</span>
                <span class="c1"># Records both losses for each epoch under the main tag &quot;loss&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">main_tag</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                                        <span class="n">tag_scalar_dict</span><span class="o">=</span><span class="n">scalars</span><span class="p">,</span>
                                        <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
            <span class="c1"># Closes the writer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># Builds dictionary with all elements for resuming training</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">,</span>
                      <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                      <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                      <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span>
                      <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">}</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># Loads dictionary</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

        <span class="c1"># Restore state for model and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># always use TRAIN for resuming training   </span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Set is to evaluation mode for predictions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> 
        <span class="c1"># Takes aNumpy input and make it a float tensor</span>
        <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># Send input to device and uses model for prediction</span>
        <span class="n">y_hat_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="c1"># Set it back to train mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># Detaches it, brings it to CPU and back to Numpy</span>
        <span class="k">return</span> <span class="n">y_hat_tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">plot_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="k">def</span> <span class="nf">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Fetches a single mini-batch so we can use add_graph</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>
            <span class="n">x_sample</span><span class="p">,</span> <span class="n">y_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">x_sample</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>vamos ahora a utilizar la clase anterior para poner en marcha nuestro proyecto. Comenzamos cargando los datos, lo hacemos con el programa Python siguiente:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">true_b</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">true_w</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Data Generation</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">true_b</span> <span class="o">+</span> <span class="n">true_w</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mf">.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Shuffles the indices</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

<span class="c1"># Uses first 80 random indices for train</span>
<span class="n">train_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="mf">.8</span><span class="p">)]</span>
<span class="c1"># Uses the remaining indices for validation</span>
<span class="n">val_idx</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="mf">.8</span><span class="p">):]</span>

<span class="c1"># Generates train and validation sets</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
<span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Que lo ejecutamos de la siguiente manera</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Runs data generation - so we do not need to copy code here</span>
<span class="o">%</span><span class="k">run</span> -i data_generation/simple_linear_regression.py
</pre></div>
</div>
</div>
</div>
<p>Ahora procedemos a preparar los datos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>

<span class="c1"># Builds tensors from numpy arrays BEFORE split</span>
<span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Builds dataset containing ALL data points</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>

<span class="c1"># Performs the split</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="mf">.8</span>
<span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_total</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">)</span>
<span class="n">n_val</span> <span class="o">=</span> <span class="n">n_total</span> <span class="o">-</span> <span class="n">n_train</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_val</span><span class="p">])</span>

<span class="c1"># Builds a loader of each set</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora procedemos a la configuración del modelo</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> model_configuration/v4.py

<span class="c1"># Sets learning rate - this is &quot;eta&quot; ~ the &quot;n&quot; like Greek letter</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Now we can create a model and send it at once to the device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Defines a SGD optimizer to update the parameters</span>
<span class="c1"># (now retrieved directly from the model)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a MSE loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">run</span> -i model_configuration/v4.py
</pre></div>
</div>
</div>
</div>
<p>Del código anterior obtenemos los objetos <em>model, loss function y optimizer</em> que vamos a pasar la clase creada anteriormente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora ya entramos en el proceso de entrenar el modelo, con el uso de la clase <em>StepBuStep</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span> <span class="o">=</span> <span class="n">StepByStep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">set_tensorboard</span><span class="p">(</span><span class="s1">&#39;classy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span> <span class="o">==</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora podemos entrenar el modelo por ejemplo con epochs = 200</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span> <span class="c1"># remember, model == sbs.model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sbs</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>También ahora podemos hacer previsiones</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">sbs</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Hacemos una salvaguarda del modelo</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="s1">&#39;model_checkpoint.pth&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Vamos a ver a continuación, cómo cargariamos de nuevo el modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_sbs</span> <span class="o">=</span> <span class="n">StepByStep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_sbs</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="s1">&#39;model_checkpoint.pth&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>En resumen y después de todo el desarrollo anterior, con todo lo construido anteriormente, lo que se puede decir es que los pasos a dar para configurar estos modelos son:</p>
<ul class="simple">
<li><p>Preparación de los datos (no generación de los mismos)</p></li>
<li><p>Configuración del modelo (función de pérdida, optimizador y modelo)</p></li>
<li><p>Entrenamiento del modelo (utilización de  de la clase StepByStep)</p></li>
</ul>
</section>
<section id="ejemplo-de-uso">
<h2><span class="section-number">6.10. </span>Ejemplo de uso.<a class="headerlink" href="#ejemplo-de-uso" title="Permalink to this heading">#</a></h2>
<p>A continuación veamos un ejemplo de datos concretos donde aplicamos lo construido hasta ahora</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># cargamos los datos</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;datos/Pecan.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Hacemos un modelo de regresión lineal simple, para ello seleccionamos las variables correspondientes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># escalamos los valores entre [0,1]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="n">X</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="o">=</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># No hacemos la validación</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>

<span class="c1"># Builds tensors from numpy arrays BEFORE split</span>
<span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Builds dataset containing ALL data points</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>


<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Now we can create a model and send it at once to the device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Defines a SGD optimizer to update the parameters</span>
<span class="c1"># (now retrieved directly from the model)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># Defines a MSE loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span> <span class="o">=</span> <span class="n">StepByStep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span> <span class="o">==</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># entrenamos el modelo</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span> <span class="c1"># remember, model == sbs.model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Observamos que los parámetros estimados del modelo de regresión son muy similares a los que se han obtenido con estos mismos datos en el tema anterior</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sbs</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="ejemplo-de-uso-regresion-multiple">
<h2><span class="section-number">6.11. </span>Ejemplo de uso regresión múltiple.<a class="headerlink" href="#ejemplo-de-uso-regresion-multiple" title="Permalink to this heading">#</a></h2>
<p>Trabajaremos con la base de datos libre <em>Boston housing prices</em> de <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html">sklearn</a>.</p>
<p><strong>DESCRIPCIÓN DE LAS VARIABLES DEL DATASET BOSTON HOUSING PRICES:</strong></p>
<ul class="simple">
<li><p>CRIM: Per capita crime rate by town</p></li>
<li><p>ZN: Proportion of residential land zoned for lots over 25,000 sq. ft</p></li>
<li><p>INDUS: Proportion of non-retail business acres per town</p></li>
<li><p>NOX: Nitric oxide concentration (parts per 10 million)</p></li>
<li><p>RM: Average number of rooms per dwelling</p></li>
<li><p>AGE: Proportion of owner-occupied units built prior to 1940</p></li>
<li><p>DIS: Weighted distances to five Boston employment centers</p></li>
<li><p>RAD: Index of accessibility to radial highways</p></li>
<li><p>TAX: full-value property-tax rate per $10,000</p></li>
<li><p>PTRATIO: Pupil-teacher ratio by town</p></li>
<li><p>B: <span class="math notranslate nohighlight">\(1000(B_k — 0.63)^2\)</span>, where Bk is the proportion of [people of African American descent] by town</p></li>
<li><p>LSTAT: Percentage of lower status of the population</p></li>
<li><p>MEDV: Median value of owner-occupied homes in $ <span class="math notranslate nohighlight">\(10^3\)</span></p></li>
</ul>
<hr class="docutils" />
<p>MEDV es la variable respuesta u objetivo de este problema de regresión  lineal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datos/Bostonraw.csv&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">lower</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="c1">#convertimos las variables a minúsculas</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Vemos que no hay ningún valor faltante</span>
<span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>   <span class="c1">#seaborn es una extensión de matplotlib</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span> 
<span class="c1"># Estuiamos los outliers existentes</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#definción de la función que nos permitirá eliminar los outliers </span>
<span class="c1">#para cada variable (columna)</span>
<span class="k">def</span> <span class="nf">eliminar_outlier</span><span class="p">(</span><span class="n">col</span><span class="p">):</span> 
    <span class="nb">sorted</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
    <span class="n">Q1</span><span class="p">,</span><span class="n">Q3</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">col</span><span class="p">,[</span><span class="mi">25</span><span class="p">,</span><span class="mi">75</span><span class="p">])</span>
    <span class="n">IQR</span><span class="o">=</span><span class="n">Q3</span><span class="o">-</span><span class="n">Q1</span>
    <span class="n">lowerthr</span><span class="o">=</span> <span class="n">Q1</span><span class="o">-</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span><span class="p">)</span> <span class="c1">#UMBRAL INFERIOR</span>
    <span class="n">upperthr</span><span class="o">=</span> <span class="n">Q3</span><span class="o">+</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span><span class="p">)</span> <span class="c1">#UMBRAL SUPERIOR</span>
    <span class="k">return</span> <span class="n">lowerthr</span><span class="p">,</span><span class="n">upperthr</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span> <span class="c1">#aplicamos la función eliminar_outlier para cada variable (columna) del dataframe</span>
    <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="s1">&#39;object&#39;</span><span class="p">:</span> 
        <span class="n">lowerthr</span><span class="p">,</span><span class="n">upperthr</span><span class="o">=</span><span class="n">eliminar_outlier</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
        <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">&gt;</span><span class="n">upperthr</span><span class="p">,</span><span class="n">upperthr</span><span class="p">,</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
        <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">&lt;</span><span class="n">lowerthr</span><span class="p">,</span><span class="n">lowerthr</span><span class="p">,</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="estandarizacion-de-los-datos">
<h3><span class="section-number">6.11.1. </span>Estandarización de los datos<a class="headerlink" href="#estandarizacion-de-los-datos" title="Permalink to this heading">#</a></h3>
<p>Hacemos un cambio de variable para que los datos tengan una media de cero y desviación típica de uno. Hacemos primero una copia de los datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfestand</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">dfestand</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span> <span class="c1">#importamos la librería para estandarizar</span>
<span class="n">scalerX</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">lista_columnas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;crim&#39;</span><span class="p">,</span> <span class="s1">&#39;zn&#39;</span><span class="p">,</span> <span class="s1">&#39;indus&#39;</span><span class="p">,</span> <span class="s1">&#39;nox&#39;</span><span class="p">,</span> <span class="s1">&#39;rm&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;dis&#39;</span><span class="p">,</span> <span class="s1">&#39;rad&#39;</span><span class="p">,</span> <span class="s1">&#39;tax&#39;</span><span class="p">,</span>
       <span class="s1">&#39;ptratio&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;lstat&#39;</span><span class="p">]</span>
<span class="n">dfestand</span><span class="p">[</span><span class="n">lista_columnas</span><span class="p">]</span> <span class="o">=</span> <span class="n">scalerX</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dfestand</span><span class="p">[</span><span class="n">lista_columnas</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Estandarizamos la variable respuesta u objetivo (variable dependiente, <strong>Y</strong>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scalerY</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">dfestand</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">scalerY</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dfestand</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dfestand</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]),</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dfestand</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>Creamos las variables explicativas X e Y</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">dfestand</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;medv&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">dfestand</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensión de X:&quot;</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensión de Y&quot;</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pasamos los datos anteriores a tensores</span>
<span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span><span class="n">y_tensor</span><span class="p">)</span>

<span class="c1"># Hacemos el split de los datos</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_total</span><span class="o">*</span><span class="n">ratio</span><span class="p">)</span>
<span class="n">n_val</span> <span class="o">=</span> <span class="n">n_total</span><span class="o">-</span><span class="n">n_train</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_val</span><span class="p">])</span>

<span class="c1"># creamos el DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Configuremos ahora el modelo</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Coeficiente de aprendizaje</span>
<span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># creamos el modelo</span>
<span class="n">par_entrada</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># es el número de variables predictoras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">par_entrada</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Hemos definido los datos y la configuración del modelo, ahora procedemos a su entrenamiento</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span> <span class="o">=</span> <span class="n">StepByStep</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
<span class="n">sbs</span><span class="o">.</span><span class="n">set_loaders</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span> <span class="o">==</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sbs</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span> <span class="c1"># remember, model == sbs.model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">sbs</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora si queremos hacer predicciones, tenemos que pasar los datos de validación <em>val_dat</em> a un array numpy. Para obtener esto debemos ejecutar el siguiente código</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dat_val</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sbs</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dat_val</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Y ahora ya podemos obtener los indicadores de ajuste del modelo que deseemos (MAE,MSE, etc).</p>
</section>
</section>
<section id="apendice">
<h2><span class="section-number">6.12. </span>Apéndice.<a class="headerlink" href="#apendice" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a href="https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/?utm_source=drip&utm_medium=email&utm_campaign=Text+Generation+with+LSTM+in+PyTorch&utm_content=Text+Generation+with+LSTM+in+PyTorch" target="_blank"> Un resumen de creación código PyTorch </a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./jupyters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Tema1regresionlineal.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Regresión lineal.</p>
      </div>
    </a>
    <a class="right-next"
       href="Tema_3_clasificacion.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Introducción problemas de clasificación.</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">6.1. Introducción.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#funciones-de-orden-alto-higher-order">6.2. funciones de orden alto (higher-order).</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-tensordataset-y-dataloader">6.3. Dataset, TensorDataset y DataLoader.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-split">6.4. Random Split.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion">6.5. Evaluación.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorboard">6.6. TensorBoard.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#add-graph">6.7. add_graph.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guardando-y-cargando-modelos">6.8. Guardando y cargando modelos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#utilizando-clases-de-python-para-construir-el-modelo">6.9. Utilizando clases de Python para construir el modelo.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-uso">6.10. Ejemplo de uso.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-uso-regresion-multiple">6.11. Ejemplo de uso regresión múltiple.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estandarizacion-de-los-datos">6.11.1. Estandarización de los datos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apendice">6.12. Apéndice.</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Francisco Rodríguez
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>