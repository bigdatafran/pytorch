{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal.\n",
    "## Introducción\n",
    "\n",
    "En el capítulo anterior, hemos visto algunas características básicas de Pytorch, como por ejemplo cómo poder construir tensores, operar con ellos, calcular derivadas, etc.\n",
    "\n",
    "En este apartado, nos adentramos un poco más en este campo y procederemos paso a paso a ver cómo poder utilizar los procedimientos que nos ofrece Pytorch para poder hacer un sencillo análisis de regresión simple, que como se sabe de lo que se trata es de encontrar los parámetros b y w de una recta de regresión que minimicen los errores (método de mínimos cuadrados ordinarios), es decir se trata de hacer mínima la función de coste:\n",
    "\n",
    "$$f.coste = \\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y}_{i}-y_{i})^{2}​$$\n",
    "\n",
    "Siendo $\\hat{y}_{i}$ el valor esperado mediante la recta de regresión:\n",
    "\n",
    "$$\\hat{y}_{i}=b+w\\cdot x_i$$\n",
    "\n",
    "Vamos inicialmente a crear de forma artificial una serie de datos para su posterior tratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_b=1 #Valor verdadero de B\n",
    "true_w=2 #Valor verdadero de w\n",
    "N = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "# Generamos números aleatorios para x\n",
    "x = np.random.rand(N,1)\n",
    "# generamos la variable de ruido\n",
    "# randn para generar datos de una distribución normal\n",
    "epsilon = (0.1*np.random.randn(N,1))\n",
    "# generamos los datos de la variable dependiente\n",
    "y = true_b + true_w * x + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos obtenidos tendrán el siguiente diagrama de dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Diagrama de dispersión de los puntos')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Valor de las x\")\n",
    "plt.ylabel(\"Valor de las y\")\n",
    "plt.title(\"Diagrama de dispersión de los puntos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la celda anterior, hemos generado 100 números de manera que tienen \"cierta dependencia lineal\" y los parámetros a los que nos \"debemos acercar\" con las estimaciones que hagamos deberán de ser: b = 1 y w=2.\n",
    "\n",
    "A continuación procedemos a generar los datos de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles de los índices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "# 80 por ciento para train\n",
    "train_idx = idx[:int(N*.8)]\n",
    "# El resto para test\n",
    "val_idx = idx[int(N*.8):]\n",
    "# Generamos el conjunto de datos de train y de test\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los tensores correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "x_train.dtype, x_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede cambiar la precisión de los números que conforman el tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor = x_train_tensor.float()\n",
    "float_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchas ocasiones hay que decidir si se trabaja en CPU o en GPU (por defecto Pytorch pone los tensores en CPU), todo depende de si se tiene o instalado *cuda*. Entonces para determinar el *device* sobre el que se puede trabajar, normalmente se ejecuta la siguiente instrucción "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se tiene más de una tarjeta gráfica, se puede saber el número y el nombre de las mismas, con las siguiente instrucción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 950M\n"
     ]
    }
   ],
   "source": [
    "n_cudas = torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso sólo se tendría una GPU con nombre *GeForce GTX 950M*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, si se tiene un tensor, que por defecto está instalado en la CPU y se quiere pasar a la GPU, la traslación se haría de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7713], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
    "gpu_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto vamos a poner nuestros datos de entrenamiento a la GPU de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Nuestros datos estaban como numpy array, pero los transformamos\n",
    "# en tensores PyTorch's y después los mandamos al device elegido\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Veamos los tipos de datos con los que trabajamos\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya habíamos apuntado en algún apartado anterior, se puede pasar un tensor a un numpy array con la propiedad numpy(), pero veamos ahora qué ocurre por ejemplo con x_train_tensor = torch.as_tensor(x_train).float().to(device) que lo hemos pasado a cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m back_to_numpy \u001b[38;5;241m=\u001b[39m \u001b[43mx_train_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "back_to_numpy = x_train_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta que nos da error y el motivo está en que de esa manera no se puede pasar de forma directa un tensor a un numpy array porque en este caso lo tenemos en la GPU. Hay que devolverlo primero a la cpu y después pasarlo a numpy array. Lo hacemos de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_numpy = x_train_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando parámetros.\n",
    "\n",
    "En este modelo de regresión los parámetros van a ser b y w y son estos dos parámetros los que debemos ir modificando para que la función de coste sea mínima. Esta minimización se va a hacer mediante el uso de derivadas, y en concreto mediante gradientes. En Pytorch para hacer esto se debe utilizar la propiedad *requires_grad = True* para conseguirlo. Esto lo vamos a hacer de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos pasar estos parámetros al device con el que estamos trabajando, realmente lo debemos hacer de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], device='cuda:0', grad_fn=<CopyBackwards>) tensor([0.1288], device='cuda:0', grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden crear de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "    dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "    dtype=torch.float, device=device)\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd es el acrónimo de *automatic differentiation package* y es el paquete que se encarga de hacer todo el proceso de cálculo de las derivadas.\n",
    "\n",
    "```{index} autograd, backward\n",
    "```\n",
    "\n",
    "Con el método *backward* lo que se consigue es calcular el valor de todos los gradientes que tengamos en el proceso de producción. En nuestro caso lo que queremos es calcular los gradientes de la función de pérdida, lo cual se realiza de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la función de cálculo\n",
    "yhat = b + w * x_train_tensor\n",
    "#Definimos el error\n",
    "error = (yhat - y_train_tensor)\n",
    "# Definimos la función de pérdida (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "#Por último calculamos el gradiente\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos a continuación los tensores que realmente están implicados en el proceso de cálculo de gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(error.requires_grad, yhat.requires_grad, \\\n",
    "b.requires_grad, w.requires_grad)\n",
    "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que de forma directa están b y w pero luego por la construcción que se ha hecho también están *error* y *yhat*.\n",
    "\n",
    "```{index} grad\n",
    "```\n",
    "El valor concreto del gradiente lo obtenemos con el método *grad* de la siguiente manera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.3881], device='cuda:0') tensor([-1.9439], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(b.grad, w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante tener en cuenta que **el cálculo de gradientes con Pytorch es acumulativo** lo cual quiere decir que si se vuelve a calcular el gradiente con las mismas instrucciones anteriores se obtiene lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7762], device='cuda:0') tensor([-3.8878], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# definimos la función de cálculo\n",
    "yhat = b + w * x_train_tensor\n",
    "#Definimos el error\n",
    "error = (yhat - y_train_tensor)\n",
    "# Definimos la función de pérdida (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "#Por último calculamos el gradiente\n",
    "loss.backward()\n",
    "\n",
    "print(b.grad, w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir se han duplicado los valores del gradiente. Por este motivo es muy importante en este tipo de trabajos tener esto en cuenta y no olvidarse de poner a cero el gradiente en cada paso. Esto se consigue con la propiedad *zero_*. Lo podemos con el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.3881], device='cuda:0') tensor([-1.9439], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# !!!!NUEVO. ponemos a cero los gradientes\n",
    "b.grad.zero_(), w.grad.zero_()\n",
    "\n",
    "\n",
    "\n",
    "# definimos la función de cálculo\n",
    "yhat = b + w * x_train_tensor\n",
    "#Definimos el error\n",
    "error = (yhat - y_train_tensor)\n",
    "# Definimos la función de pérdida (MSE)\n",
    "loss = (error ** 2).mean()\n",
    "#Por último calculamos el gradiente\n",
    "loss.backward()\n",
    "\n",
    "print(b.grad, w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí podemos ver que hemos puesto al comienzo del código el contador a cero y ya obtenemos el mismo valor que al comienzo. \n",
    "\n",
    "## Actualizando lo parámetros.\n",
    "\n",
    "En este tipo de trabajo, la optimización se va haciendo de forma iterativa y siguiendo el sentido que nos va marcando el valor del gradiente y para hacer esto se necesita operar con la denominada *tasa de aprendizaje* o *learning rate* que la vamos a designar por *lr*. Entonces de forma iterativa vamos a hacer converger hacia los valores óptimos mediante la siguiente transformación que se hace en cada paso:\n",
    "\n",
    "$$b = b-lr\\cdot b.grad$$\n",
    "\n",
    "$$w = w-lr\\cdot w.grad$$\n",
    "\n",
    "Esto lo hacemos utilizando el código siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Definimos learning rate\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient\n",
    "    # descent. How wrong is our model? That's the error!\n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    # No more manual computation of gradients! \n",
    "    # b_grad = 2 * error.mean()\n",
    "    # w_grad = 2 * (x_tensor * error).mean()   \n",
    "    # We just tell PyTorch to work its way BACKWARDS \n",
    "    # from the specified loss!\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. But not so fast...\n",
    "    # FIRST ATTEMPT - just using the same code as before\n",
    "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
    "    # b = b - lr * b.grad\n",
    "    # w = w - lr * w.grad\n",
    "    # print(b)\n",
    "\n",
    "    # SECOND ATTEMPT - using in-place Python assigment\n",
    "    # RuntimeError: a leaf Variable that requires grad\n",
    "    # has been used in an in-place operation.\n",
    "    # b -= lr * b.grad\n",
    "    # w -= lr * w.grad        \n",
    "    \n",
    "    # THIRD ATTEMPT - NO_GRAD for the win!\n",
    "    # We need to use NO_GRAD to keep the update out of\n",
    "    # the gradient computation. Why is that? It boils \n",
    "    # down to the DYNAMIC GRAPH that PyTorch uses...\n",
    "    with torch.no_grad():\n",
    "        b -= lr * b.grad\n",
    "        w -= lr * w.grad\n",
    "    \n",
    "    # PyTorch is \"clingy\" to its computed gradients, we\n",
    "    # need to tell it to let it go...\n",
    "    b.grad.zero_()\n",
    "    w.grad.zero_()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver en la salida de este código el resultado que obtenemos para los parámetros b y w están muy cercanos a los valores que inicialmente se les ha dado (recordar que a b se le había asignado un valor de 1 y a w de 2 para generar los datos artificiales del modelo). \n",
    "\n",
    "Como se ha podido ver en el código anterior, casi todos los pasos se a hecho de forma manual, pero Pytorch tiene muchas estructuras que nos facilitan todos o casi todos estos procesos. A continuación procedemos a modificar el código anterior para in introduciendo herramientas de Pytorch con las que nos debemos ir familiarizando.\n",
    "\n",
    "## Otimizadores.\n",
    "\n",
    "Pytorch ya viene cargado con una serie de optimizadores, que <a href=\"https://pytorch.org/docs/stable/optim.html\" target=\"_blank\"> podemos encontrar en este enlace </a>. Uno de estos optimizadores es *Stochastic Gradient Descend (SGD)* que vamos a utilizar para llegar a optimizar la búsqueda de los parámetros b y w. También **muy importante**, al final de cada iteración no olvidarse de utilizar la propiedad *zero_grad* para poner a cero el gradiente. Este optimizador se va a definir de la siguiente manera:\n",
    "\n",
    "optimizer = optim.SGD([b,w],lr=lr)\n",
    "\n",
    "A continuación veamos cómo se implementa en el código anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "### ¡¡¡ IMPORTANTE importar esto\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# AQUI INCLUIMOS EL OPTIMIZADOR\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # We are using ALL data points, so this is BATCH gradient \n",
    "    # descent. How wrong is our model? That's the error! \n",
    "    error = (yhat - y_train_tensor)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate. No more manual update!\n",
    "    # with torch.no_grad():\n",
    "    #     b -= lr * b.grad\n",
    "    #     w -= lr * w.grad\n",
    "    optimizer.step()\n",
    "    \n",
    "    # No more telling Pytorch to let gradients go!\n",
    "    # b.grad.zero_()\n",
    "    # w.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida.\n",
    "\n",
    "Igualmente Pytorch dispone de una buena <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\" target=\"_blank\"> cantidad de funciones de pérdida</a> y en esta sección vamos a ver cómo poderla introducir en nuestro código para tener que evitar escribir nosotros mismos esa función.\n",
    "\n",
    "Como lo que necesitamos es minimmizar la suma de cuadrados (MSE) la función de pérdida que se va a utilizar <a \"href=https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss\" target=\"_blank\"> es nn.MSELoss </a>.\n",
    "\n",
    "El formato que vamos a emplear es el siguiente:\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "Veamos a continuación en nuestro ejemplo cómo introducimos este nuevo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "b = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "w = torch.randn(1, requires_grad=True, \\\n",
    "                dtype=torch.float, device=device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([b, w], lr=lr)\n",
    "\n",
    "# ¡¡¡¡NUEVO. introducimos la función de pérdida.. Mean squaret error (media cuadrática)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = b + w * x_train_tensor\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    # No more manual loss!\n",
    "    # error = (yhat - y_train_tensor)\n",
    "    # loss = (error ** 2).mean()\n",
    "    # ¡¡¡¡¡NUEVO utilizamos la función de pérdida\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos cuanto vale la función de pérdida\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos qué pasa si lo pasamos a un numpy array como hemos dicho anteriormente (tenemos en este caso un error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "loss.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un error porque este tensor esta afectado por el cálculo de los gradientes, entonces para conseguir nuestro objetivo lo que tenemos que hacer es lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.00804466, dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos emplear los métodos *item()* o *tilist()* para obtener un valor determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008044655434787273 0.008044655434787273\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo.\n",
    "\n",
    "El modelo lo vamos a utilizar en principio para definir los parámetros y actualizar la función de regresión. Este modelo no es más que una clase de Python  que hereda de la clase *nn.Module*. Veamos cómo la definimos en nuestro caso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module): # La herencia\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"b\" and \"w\" real parameters of the model,\n",
    "        # we need to wrap them with nn.Parameter\n",
    "        # definimos los parámetros\n",
    "        self.b = nn.Parameter(torch.randn(1,\n",
    "                                          requires_grad=True, \n",
    "                                          dtype=torch.float))\n",
    "        self.w = nn.Parameter(torch.randn(1, \n",
    "                                          requires_grad=True,\n",
    "                                          dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        # Devuelve el valor de la regresión\n",
    "        return self.b + self.w * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al heredar de <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\" target=\"_blank\"> *nn.Module* </a> podemos utilizar el método *parameters()*, obteniendo el siguiente resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dummy = ManualLinearRegression()\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{index} Entry name\n",
    "```\n",
    "\n",
    "También podemos obtener el valor actual de los parámetros mediante el método *state_dict()*. Veamoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('b', tensor([0.3367])), ('w', tensor([0.1288]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los valores del optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pasar nuestro modelo a un device lo debemos hacer de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Creates a \"dummy\" instance of our ManualLinearRegression model\n",
    "# and sends it to the device\n",
    "dummy = ManualLinearRegression().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final nuestro código nos quedaría de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('b', tensor([1.0235], device='cuda:0')), ('w', tensor([1.9690], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device) ## NUEVO AÑADIDO\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # What is this?!?\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    # No more manual prediction!\n",
    "    yhat = model(x_train_tensor) ## NUEVO AÑADIDO\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and\n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar en el código anterior que hemos añadido *model.train()*, esto es una buena práctica para indicar que estamos en un proceso de entrenamiento de modelo.\n",
    "\n",
    "## Definición de redes neuronales.\n",
    "\n",
    "En los códigos anteriores, nosotros mismos hemos procedido a generar de manera manual la ecuación de regresión, sin embargo este procedimiento se puede omitir y utilizar para ello la posibilidad de definir una red neuronal adecuada para este problema. Lo haremos con el modelo *Linear* de Pytorch.\n",
    "\n",
    "En este caso se necesita definir una *feature* de entrada y otra de salida, lo haremos así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(1, 1)\n",
    "linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los parámetros que antes hemos definido como b y w de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[-0.2191]])), ('bias', tensor([0.2018]))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el parámetro b sería reconocido mediante *bias* y el w mediante *weight*. Ahora se podría construir el modelo definiéndolo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear model\n",
    "        # with a single input and a single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call\n",
    "        self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cuales son ahora los parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.7645]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.8300], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dummy = MyLinearRegression().to(device)\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('linear.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos secuenciales.\n",
    "\n",
    "El ejemplo anterior es un sencillo ejemplo de red neuronal muy simple. Estas redes se pueden complicar todo lo que queramos, pero existen unos modelos denominados secuenciales que engloban al modelo definido anteriormente. Estos modelos se construyen con la expresión *nn.Sequential()* y como parámetro se le puede añadir el modelo lineal que se desee probar. Por ejemplo en nuestro caso, ese modelo se puede definir de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('0.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Alternatively, you can use a Sequential model\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de modelos se pueden combinar entre sí para construir redes neuronales que se agrupan en diversas capas como puede verse en la siguiente figura.\n",
    "\n",
    "![redes neuronale](figuras/redes.PNG)\n",
    "\n",
    "En ejemplo anterior, tendremos una red neuronal con una capa de entrada que se definiría por *nn.Linear(3,5)* (ya que tiene 3 inputs y genera 5 salidas o output), en el medio tiene una capa oculta y se genera una salida de una unidad, quedaría definida como *nn.Linear(5,1)*. Podriamos concatenar todo esto mediante un modelo secuencial de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4414,  0.4792, -0.1353],\n",
       "                      [ 0.5304, -0.1265,  0.1165],\n",
       "                      [-0.2811,  0.3391,  0.5090],\n",
       "                      [-0.4236,  0.5018,  0.1081],\n",
       "                      [ 0.4266,  0.0782,  0.2784]], device='cuda:0')),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0815,  0.4451,  0.0853, -0.2695,  0.1472], device='cuda:0')),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2060, -0.0524, -0.1816,  0.2967, -0.3530]], device='cuda:0')),\n",
       "             ('1.bias', tensor([-0.2062], device='cuda:0'))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential(nn.Linear(3, 5), nn.Linear(5, 1)).to(device)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir el anterior modelo no hemos dado nombre a las diferentes capas, por lo que las nombra mediante una serie de etiquetas numéricas. Se puede usar el método *add_module()* para añadir capas con un nombre determinado de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layer1): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Building the model from the figure above\n",
    "model = nn.Sequential()\n",
    "model.add_module('layer1', nn.Linear(3, 5))\n",
    "model.add_module('layer2', nn.Linear(5, 1))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todos los elementos indicados anteriormente ya tenemos conocimiento más que suficiente para poder montar de forma adecuada nuestro modelo de regresión lineal simple. Para hacer esto, dividiremos el trabajo en tres partes:\n",
    "\n",
    "* Preparación de los datos\n",
    "\n",
    "* Configuración del modelo\n",
    "\n",
    "* Entrenamiento del modelo\n",
    "\n",
    "Veremos cada una de las tres partes en los próximos apartados, pero antes de seguir adelante y puesto que lo utilizaremos posteriormente, conviene explicar una serie de *comandos mágicos de jupyter* ya que gracias a ellos mejoraremos el conocimiento del proceso de construcción de este tipo de redes.\n",
    "\n",
    ":::{note}\n",
    "* %writefile . Lo que hace es guardar en un fichero el contenido de la celda, de esa manera depués lo podremos ejecutar\n",
    "\n",
    "* %run. Ejecuta el fichero que se le indica en este comando, y si además se utiliza %run -i tiene en cuenta los valores de todas las variables con las que se esté trabajando en jupyter notebook.\n",
    "\n",
    "Gracias a este sistema, vamos a poder ir construyendo y mejorando modelos sobre otros sin que tengamos que repetir código.\n",
    ":::\n",
    "\n",
    "Así que de esta manera, procedemos a elaborar nuestro artefacto de trabajo, construyendo los tres elementos indicados anteriormente.\n",
    "\n",
    "## Preparación de lo datos.\n",
    "\n",
    "En este paso incorporamos los siguientes comandos:\n",
    "\n",
    "**NOTA:** Antes de ejecutar la celda siguiente hay que crear una carpeta denominada *data_preparation* contenida en la misma carpeta que contiene este jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v0.py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Our data was in Numpy arrays, but we need to transform them\n",
    "# into PyTorch's Tensors and then we send them to the\n",
    "# chosen device\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si queremos ejecutar el trozo de código anterior, lo haríamos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de modelo.\n",
    "\n",
    "En este segundo apartado, vamos a definir los siguientes elementos:\n",
    "\n",
    "* Un modelo\n",
    "\n",
    "* Una función de pérdida (loss function).\n",
    "\n",
    "* Un optimizador\n",
    "\n",
    "Todo lo anterior lo tenemos en el siguiente código (construir antes una carpeta denominada *model_configuration*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v0.py\n",
    "\n",
    "# This is redundant now, but it won't be when we introduce\n",
    "# Datasets...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters \n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo ejecutamos mediante \n",
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de entrenamiento\n",
    "\n",
    "El modelo lo construimos así (antes se debe crear la carpeta *model_training*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v0.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo ejecutamos mediante\n",
    "%run -i model_training/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso de este método.\n",
    "\n",
    "En los anteriores apartados hemos creado y estimado los parámetros de una regresión lineal simple en base a unos datos sintéticos. En este apartado vamos a aplicar lo visto en los anteriores apartados, pero a datos provenientes de un fichero de datos real. Este fichero de datos lo obtenemos de los ficheros que por defecto contiene scikit learn. Lo hacemos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Water per acre</th>\n",
       "      <th>Salinity level</th>\n",
       "      <th>Fertilizer per acre</th>\n",
       "      <th>Pecan Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.138954</td>\n",
       "      <td>45.916165</td>\n",
       "      <td>42.896806</td>\n",
       "      <td>406.064207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.907342</td>\n",
       "      <td>42.998570</td>\n",
       "      <td>49.763432</td>\n",
       "      <td>442.476260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.301620</td>\n",
       "      <td>43.715734</td>\n",
       "      <td>48.242166</td>\n",
       "      <td>433.672569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.255560</td>\n",
       "      <td>35.568128</td>\n",
       "      <td>53.779698</td>\n",
       "      <td>467.941026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.998049</td>\n",
       "      <td>24.689234</td>\n",
       "      <td>50.967590</td>\n",
       "      <td>510.038689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Water per acre  Salinity level  Fertilizer per acre  Pecan Production\n",
       "0       68.138954       45.916165            42.896806        406.064207\n",
       "1       79.907342       42.998570            49.763432        442.476260\n",
       "2       75.301620       43.715734            48.242166        433.672569\n",
       "3       91.255560       35.568128            53.779698        467.941026\n",
       "4      100.998049       24.689234            50.967590        510.038689"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargamos los datos\n",
    "df = pd.read_csv(\"datos/Pecan.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x214597d62b0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[\"Fertilizer per acre\"],df[\"Pecan Production\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el gráfico anterior, podemos ver que la nube de puntos se puede ajustar bien mediante un modelo de regresión lineal simple. Como este ejemplo está hecho sólo con fines didácticos, y además no contamos con muchos puntos, no vamos a dividir el conjunto de datos entre entrenamiento y test, simplemente vamos a ver qué parámetros se estiman mediante scikit-learn y los comparamos con los que se obtienen con un modelo de redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.values[:, 2].reshape(-1,1)\n",
    "y= df.values[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# escalamos los valores entre [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X=df.values[:, 2].reshape(-1,1)\n",
    "X=scaler.fit_transform(X)\n",
    "y= df.values[:,3].reshape(-1,1)\n",
    "y=scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.19635686]]\n"
     ]
    }
   ],
   "source": [
    "# Parámetro del modelo\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0730295]\n"
     ]
    }
   ],
   "source": [
    "# Parámetro intercepto\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto datos vamos a construir la red neuronal correspondiente y proceder a la estimación de los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# preparación del modelo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#X=df.values[:, 2].reshape(-1,1)\n",
    "#y= df.values[:,3].reshape(-1,1)\n",
    "x_train_tensor2 = torch.as_tensor(X).float().to(device)\n",
    "y_train_tensor2= torch.as_tensor(y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('0.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes model's predicted output - forward pass\n",
    "    yhat = model(x_train_tensor2)\n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(yhat, y_train_tensor2)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and \n",
    "    # the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.1963]], device='cuda:0')),\n",
       "             ('0.bias', tensor([-0.0730], device='cuda:0'))])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apéndice.\n",
    "\n",
    "* <a href=\"https://machinelearningmastery.com/making-predictions-with-multilinear-regression-in-pytorch/?utm_source=drip&utm_medium=email&utm_campaign=Making+predictions+with+multilinear+regression+in+PyTorch&utm_content=Making+predictions+with+multilinear+regression+in+PyTorch\" target=\"_blank\"> Haciendo predicciones </a>\n",
    "\n",
    "* <a href=\"https://machinelearningmastery.com/training-a-single-output-multilinear-regression-model-in-pytorch/?utm_source=drip&utm_medium=email&utm_campaign=Making+predictions+with+multilinear+regression+in+PyTorch&utm_content=Making+predictions+with+multilinear+regression+in+PyTorch\" target=\"_blanK\">Entrenando el modelo de regresión multilineal en pyTorch</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
