{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2\n",
    "\n",
    "## Introducción.\n",
    "\n",
    "En este tema continuaremos mejorando y optimizando la generación de código que se ha mostrado en el tema anterior. Lo primero que vamos a hacer es cargar una serie de librerías que son las que vamos a necesitar, y el código además lo vamos a guardar para reutilizarlo es códigos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting librerias/v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile librerias/v0.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i librerias/v0.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones de orden alto (higher-order).\n",
    "\n",
    "Para el desarrollo que queremos hacer posteriormente necesitamos antes introducir una herramienta muy poderosa de Python que consiste en las funciones de alto nivel, o también funciones anidadas, las cuales nos permiten devolver funciones mediante la llamada a otra función.\n",
    "\n",
    "Veamos el siguiente ejemplo, en el que queremos utilizar la función de exponenciación. Esta función necesita dos parámetros para su ejecución, por un lado estaría el valor de la base y por otro el exponente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiation_builder(exponent):\n",
    "    def skeleton_exponentiation(x):\n",
    "        return x ** exponent\n",
    "    return skeleton_exponentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse en ese código tenemos definido una jerarquía de funciones, de manera que si llamamos a *exponentiation_builder* lo que nos devuelve es otra función pero ya con un determinado exponente. Veamoslo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exponentiation_builder.<locals>.skeleton_exponentiation(x)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expo = exponentiation_builder(4)\n",
    "expo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos ahora nos está devolviendo una referencia a otra función y se puede utilizar como si de una función se tratara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expo(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente con todo este código lo que hemos hecho es calcular $2^4$. Este tipo de funciones anidadas nos va a servir mucho para poder modificar con funciones aspectos tales como la función de coste a utilizar, el optimizador a emplear, etc.\n",
    "\n",
    "Entonces utilizando esta idea, procedemos a definir dos funciones anidadas que nos permitirán modificar diferentes operadores cuando procedemos a hacer el entrenamiento de un modelo. Estas funciones son las siguientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting funciones/make_train_step_fn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile funciones/make_train_step_fn.py\n",
    "\n",
    "def make_train_step_fn(model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Los parámetros de entrada son un modelo, una función de pérdida y un optimizador\n",
    "    \"\"\"\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step_fn(x, y):\n",
    "        ## X son los datos del train (var independiente)\n",
    "        ## y los valores esperados (var. dependiente)\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "        loss.backward()\n",
    "        # Step 4 - Updates parameters using gradients and the learning rate\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Devuelve los valores de la función de pérdida\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/make_train_step_fn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las funciones indicadas en el bloque anterior, introducimos una gran flexibilidad al modelo, ya que mediante la función más externa podemos pasar el modelo, la función de pérdida y el optimizador, para después con la salida que no de pasarle los datos de la variable independiente y los valores previsto. Con todo ello ya podríamos entrenar nuestro modelo.\n",
    "\n",
    "Vamos a ver ahora cómo lo podríamos utilizar de una forma práctica.\n",
    "\n",
    "Primero ejecutamos el fichero de preparación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v0_0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v0_0.py\n",
    "\n",
    "import numpy as np\n",
    "true_b=1 #Valor verdadero de B\n",
    "true_w=2 #Valor verdadero de w\n",
    "N = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "# Generamos números aleatorios para x\n",
    "x = np.random.rand(N,1)\n",
    "# generamos la variable de ruido\n",
    "# randn para generar datos de una distribución normal\n",
    "epsilon = (0.1*np.random.randn(N,1))\n",
    "# generamos los datos de la variable dependiente\n",
    "y = true_b + true_w * x + epsilon\n",
    "\n",
    "# Shuffles de los índices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "# 80 por ciento para train\n",
    "train_idx = idx[:int(N*.8)]\n",
    "# El resto para test\n",
    "val_idx = idx[int(N*.8):]\n",
    "# Generamos el conjunto de datos de train y de test\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%run -i data_preparation/v0_0.py\n",
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación creamos la configuración del modelo y al final del código utilizamos la función *make_train_step_fn* creada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "### OJO aquí está la llamada a la función anidada creada anteriormente\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior se ejecutaría de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué tiene la variables *train_step_fn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_train_step_fn.<locals>.perform_train_step_fn(x, y)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces teniendo en cuenta todo estos, ahora ya podemos crear nuestro módulo de entrenamiento, y además podemos ir recogiendo los valores de la función de pérdida en una lista para por ejemplo ir viendo cómo va su evolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step_fn(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# vemos los valores de model\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que en los pasos anteriores, hemos separado los tres pasos que aconsejamos dar en el capítulo anterior para construir estos modelos.\n",
    "\n",
    "* Preparación de los datos. \n",
    "\n",
    "* Configuración del modelo. \n",
    "\n",
    "* Entrenamiento del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(dataset)=\n",
    "## Dataset, TensorDataset y DataLoader.\n",
    "\n",
    "```{index} Dataset,TensorDataset, DataLoader\n",
    "```\n",
    "En apartados anteriores hemos trabajado con datos almacenados como dataframe, numpy array o como tensores, pero Pytorch también dispone de herramientas para adaptar de una forma mejor los datos para posteriormente poder ser tratados de una forma más eficiente, sobre todo si se trata de grandes volúmenes de datos.  En este apartado vamos a exponer las posibilidades que nos ofrece Pytorch para ello.\n",
    "\n",
    "En Pytorch, un dataset está representado por una clase de Python que hereda de la clase *Dataset*. Se puede pensar en este tipo de estructura de datos como una lista de tuplas y cada elemento de esa lista corresponde a un punto, en el *formato (features, label)*.\n",
    "\n",
    "Los métodos más fundamentales de esta clase son:\n",
    "\n",
    "* **__init__(self)**: Es el método de inicialización de una clase Python y toma los argumentos necesarios para construir una lista de tuplas. puede ser el nombre de un archivo CSV que será cargado y procesado; puede ser dos tensores, uno para las características otro para las etiquetas; o cualquier otra cosa, dependiendo de la tarea que se quiera realizar.\n",
    "\n",
    "* **__get_item__(self,index)**. Con este método el dataset puede ser indexado y poder trabajar como una lista de tuplas (features, labels). <a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\" target=\"_blank\"> En este enlace se puede ver un ejemplo </a>.\n",
    "\n",
    "* **__len__(self)**. Simplemente debería devolver el tamaño de todo el conjunto de datos, de modo que, siempre que se muestree, su indexación se limite al tamaño real.\n",
    "\n",
    "Con estas ideas, a continuación procedemos a crear una clase de Python que se encargara de crear un dataset que va a tomar dos tensores como argumentos: Los datos de la x y los datos de la y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        # Devuelve un par (feature, label) como se ha dicho antes\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante todo lo anterior, y con el fin de facilitar aún más la tarea, Pytorch tiene una clase denominada *TensorDataset* que no requiere una construcción previa de ningún tipo de clase ad hoc de Python. La forma de utilizar esta clase es la que a continuación se muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo lo hecho hasta ahora está muy bien,pero hay que tener en cuenta que hemos utilizado **todos los datos** de entrenamiento en cada de entrenamiento. Ha sido el descenso de gradiente por lotes (batch gradient descent) todo el tiempo.\n",
    "\n",
    "Esto está bien para y no da problemas para un conjunto de datos ridículamente pequeño, con el que se trabajado hasta ahora, pero si queremos ir en serio sobre todo esto y tenemos una gran cantidad de datos, debemos usar el descenso de gradiente en mini lotes. Por lo tanto, necesitamos mini-lotes (mini-batch gradient descent). Por lo tanto, tenemos que cortar nuestro conjunto de datos en consecuencia con los datos que tenemos y la capacidad de nuestro equipo.\n",
    "\n",
    "Realmente lo que necesitamos es que nuestro cargador se comporte como un iterador, por lo que podemos hacer un bucle sobre él y obtener un mini-lote diferente en cada pasada del iterador. Lo más normal es utilizar en cada iteración conjuntos de datos (mini-batch) que ocupen un múltiplo de 2 : 16,32,64 o 128. Para conseguir esto utilizamos la clase *DataLoader*, y a continuación mostramos un ejemplo de uso de la misma.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el contenido, vamos a ejecutar la siguiente instrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2809],\n",
       "         [0.3253],\n",
       "         [0.1560],\n",
       "         [0.5924],\n",
       "         [0.0651],\n",
       "         [0.8872],\n",
       "         [0.4938],\n",
       "         [0.0055],\n",
       "         [0.1409],\n",
       "         [0.0885],\n",
       "         [0.1849],\n",
       "         [0.7290],\n",
       "         [0.8662],\n",
       "         [0.3117],\n",
       "         [0.6842],\n",
       "         [0.1987]]),\n",
       " tensor([[1.5846],\n",
       "         [1.8057],\n",
       "         [1.2901],\n",
       "         [2.1687],\n",
       "         [1.1559],\n",
       "         [2.8708],\n",
       "         [1.9060],\n",
       "         [1.0632],\n",
       "         [1.1211],\n",
       "         [1.0708],\n",
       "         [1.5888],\n",
       "         [2.4927],\n",
       "         [2.6805],\n",
       "         [1.7637],\n",
       "         [2.3492],\n",
       "         [1.2654]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos devuelve una lista conteniendo dos tensores, el primer tensor conteniendo las *features* y el segundo los *labels*.\n",
    "\n",
    "Como puede verse, para trabajar con este tipo de carga de datos hay que manejar los <a href=\"https://realpython.com/python-for-loop/#iterables\" href=\"_blank\"> iterables </a> y los <a href=\"https://realpython.com/python-for-loop/#iterators\" target=\"_blank\"> iterartors </a> de Python.\n",
    "\n",
    "También se puede ver su contenido utilizando *enumerate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7852],\n",
      "        [0.8022],\n",
      "        [0.6075],\n",
      "        [0.1997],\n",
      "        [0.3309],\n",
      "        [0.6376],\n",
      "        [0.4722],\n",
      "        [0.2809],\n",
      "        [0.4938],\n",
      "        [0.5427],\n",
      "        [0.1560],\n",
      "        [0.1987],\n",
      "        [0.3745],\n",
      "        [0.0885],\n",
      "        [0.7320],\n",
      "        [0.8872]])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs,targets) in enumerate(train_loader):\n",
    "    if i==0:\n",
    "        print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces adaptando todos estos elementos para el ejemplo que estamos construyendo, podríamos definir el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Builds Dataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho esto necesitamos modificar el código del apartado de código de entrenamiento para adaptarlo a la entrada de datos de tipo mini-batch que antes ya se ha presentado. Entonces primero cargamos la parte de configuración (recordemos que aquí lo que hacemos es definir la función de coste, el modelo y el optimizador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora ya adoptamos la parte de entrenamiento para que pueda operar con la entrada de datos en formato mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Performs one train step and returns the corresponding loss \n",
    "        # for this mini-batch\n",
    "        ### La función train_step_fn se ha definido antes dentro de la jerarquía de funciones\n",
    "        mini_batch_loss = train_step_fn(x_batch, y_batch) \n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    # Computes average loss over all mini-batches - that's the epoch loss\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    \n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9696]], device='cuda:0')), ('0.bias', tensor([1.0243], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recapitulemos todos los códigos guardados hasta la fecha y pongámoslo en marcha. Lo hacemos en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/make_train_step_fn.py\n",
    "%run -i data_preparation/v0_0.py\n",
    "%run -i librerias/v0.py\n",
    "%matplotlib inline\n",
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py\n",
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el entrenamiento del modelo ahora emplea más tiempo que antes, el motivo no es otro que el bucle Mini-Batch que ahora hacemos ralentiza el proceso, ya que en total debemos hacer ahora un total de 5 ciclos (80/16=5).\n",
    "\n",
    "Otra modulación que podemos hacer en este programa es la etapa del Mini-Bach. Si tenemos en cuenta que esta etapa está definida por los siguientes elementos:\n",
    "\n",
    "* El **device** al cual se envían los datos.\n",
    "\n",
    "* Un **data loader** donde se definen los Mini-Batches\n",
    "\n",
    "* Una *función step* que devuelve los correspondientes *loss*.\n",
    "\n",
    "Podemos integrar todos los componentes dentro de una función que tenga por parámetros los elementos antes indicados y de esta manera podremos encapsular el código de una forma adecuada. Lo hacemos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting funciones/mini_batch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile funciones/mini_batch.py\n",
    "\n",
    "def mini_batch(device, data_loader, step_fn):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/mini_batch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces con este cambio el modelo de entrenamiento quedaría de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9696]], device='cuda:0')), ('0.bias', tensor([1.0260], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los módulos que deberiamos ejecutar para obtener todos los resultados vistos hasta ahora serían los siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/make_train_step_fn.py\n",
    "%run -i data_preparation/v0_0.py\n",
    "%run -i librerias/v0.py\n",
    "%matplotlib inline\n",
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py\n",
    "%run -i funciones/mini_batch.py\n",
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9684]], device='cuda:0')), ('0.bias', tensor([1.0219], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split.\n",
    "\n",
    "```{index} Random Split\n",
    "```\n",
    "\n",
    "Meadiante *Random Split* que nos proporciona pycharm, podemos hacer una división de los datos entre los que sirven de entrenamiento y los de validación, sin tener que utilizar herramientas de otras librerías. La forma de hacerlo la podemos ver en el código siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación.\n",
    "\n",
    "Una vez configurado el modelo, es la hora de hacer su evaluación con datos que no se han utilizado en su creación. En la evaluación debemos calcular para los datos de evaluación el valor que predice el modelo y compararlo con el valor real y de ahí poder sacar los indicadores de evaluación correspondientes. \n",
    "\n",
    "Para hacer las evaluaciones del modelo debemos utilizar el código *model.eval()* con la finalidad de que no se calculen los gradientes, o que los mimos sean igual a cero con lo cual conseguiremos que los pesos o parámetros del modelo sean los mismos que los que ya se han calculado durante la etapa de entrenamiento del mismo.\n",
    "\n",
    "Definimos a continuación un función de ayuda para la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting funciones/make_val_step_fn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile funciones/make_val_step_fn.py\n",
    "\n",
    "def make_val_step_fn(model, loss_fn):\n",
    "    # Builds function that performs a step in the validation loop\n",
    "    def perform_val_step_fn(x, y):\n",
    "        # Sets model to EVAL mode\n",
    "        model.eval() ### OJO aqui para indica que estamos en la evaluación\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/make_val_step_fn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora procedemos a modificar el código de nuestro modelo de configuración de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos implementar nuestro código de entrenamiento, teniendo también en cuenta el proceso de validación del modelo. El código que utilizaremos sería el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Paso de validación VALIDATION (lo incorporo ahora)\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad(): #!!!! Ojo muy importante para no calcular los gradientes\n",
    "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy importante en el código anterior. Cuando introducimos el entorno *with torch.no_grad()* lo que hacemos es no computar los gradientes y por lo tanto los parámetros se mantendrán en los calculados por el modelo en la etapa del entrenamiento.\n",
    "\n",
    "Después de hacer todos estos cambios, nuestra etapa actual en la que nos llegamos, se reproduce de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i funciones/make_train_step_fn.py\n",
    "%run -i funciones/make_val_step_fn.py\n",
    "%run -i data_preparation/v0_0.py\n",
    "%run -i librerias/v0.py\n",
    "%matplotlib inline\n",
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v2.py\n",
    "%run -i funciones/mini_batch.py\n",
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9438]], device='cuda:0')), ('0.bias', tensor([1.0287], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ahora comparar los valores de Loss que se han obtenido tanto para los datos de entrenamiento como de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses, val_losses):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.plot(losses, label='Training Loss', c='b')\n",
    "    plt.plot(val_losses, label='Validation Loss', c='r')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_losses(losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard.\n",
    "\n",
    "```{index} TensorBoard\n",
    "```\n",
    "\n",
    "TensorBoard es un magnifica herramienta a utilizar dentro de deeplearning. En este apartartaddo vamos a manejarla desde dos puntos de vista. Uno en el entorno de Jupyter notebook y otro de forma independiente.\n",
    "\n",
    "Comenzamos a utilizarla desde Jupyter Notebook, para ello necesitaremos una serie de comandos mágicos, que a continuación se procede a explicar.\n",
    "\n",
    "Primero incluimos la extensión para jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora ya podremos usar tensorboard de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ddf991f9a47bf9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ddf991f9a47bf9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De momento no nos facilita ningún tipo de información ya que no hemos enviado ningún datos a la carpeta *runs*, posteriormente cuando lo hagamos nos ofrecerá diversas opciones muy interesantes para el trabajo con tensores.\n",
    "\n",
    "También lo podemos activar de forma separada, para ello lo que hay que ejecutar en una linea de comandos es la instrucción: *tensorboard --logdir runs* y entonces en la pantalla de comandos nos aparecerán los siguientes mensajes:\n",
    "\n",
    "![Tensor Board](figuras/tensorBoard.PNG)\n",
    "\n",
    "Ahora nos debemos ir a un navegador web e introducir en la barra de direcciones *http://localhost:6006/* para ver en dicho navegador una imagen similar a la que se nos ha presentado anteriormente en una celda de este jupyter.\n",
    "\n",
    "```{index} SummaryWriter\n",
    "```\n",
    "\n",
    "Recordemos que le hemos indicado a tensorFlow que todos nuestros logs para este trabajo se encuentran en la carpeta denominada *runs*. Entonces debemos comenzar por por la creación de un <a href=\"https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter\" target=\"_blank\"> *SummaryWriter* </a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SummaryWriter implementa diferentes métodos que permiten enviar información a dashboart\n",
    "\n",
    "![metodos tensorFlow](figuras/metodoTF.PNG)\n",
    "\n",
    "También implementa otros dos métodos para la escritura efectiva de datos en disco\n",
    "\n",
    "* flush\n",
    "\n",
    "* close\n",
    "\n",
    "Utilizaremos los dos primeros métodos (add_graph y add_scalars) para enviar el gráfico de nuestro modelo (aunque no es lo mismo que el gráfico de que dibujamos con make_dot...) y, por supuesto, los dos escalares: training y validación losses.\n",
    "\n",
    "## add_graph.\n",
    "\n",
    "Añadimos información para tensorboard de la siguiente manera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_kwarg_inputs should be a dict\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "example_kwarg_inputs should be a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\Pytorch\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:841\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    837\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[1;32m--> 841\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m     )\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[1;32mD:\\MisTrabajos\\Pytorch\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:343\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurs, No graph saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28mprint\u001b[39m(graph)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\Pytorch\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:337\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 337\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[0;32m    339\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\Pytorch\\pytorch\\lib\\site-packages\\torch\\jit\\_trace.py:793\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    791\u001b[0m             example_inputs \u001b[38;5;241m=\u001b[39m example_kwarg_inputs\n\u001b[0;32m    792\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 793\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[0;32m    795\u001b[0m         func,\n\u001b[0;32m    796\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m         _store_inputs\u001b[38;5;241m=\u001b[39m_store_inputs\n\u001b[0;32m    806\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m ):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: example_kwarg_inputs should be a dict"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos nos genera un error, debido a que necesitamos enviar algún input junto con nuestro modelo. Lo solucionamos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching a tuple of feature (dummy_x) and label (dummy_y)\n",
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "# Since our model was sent to device, we need to do the same\n",
    "# with the data.\n",
    "# Even here, both model and data need to be on the same device!\n",
    "writer.add_graph(model, dummy_x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars('loss', {'training': loss, 'validation': val_loss}, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no me sale lo dejo aquí el tema de tensorboard. Sin embargo sigo actualizando el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step_fn = make_val_step_fn(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "writer.add_graph(model, x_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step_fn)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step_fn)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Records both losses for each epoch under the main tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "# Closes the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9432]], device='cuda:0')), ('0.bias', tensor([1.0263], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardando y cargando modelos.\n",
    "\n",
    "Vamos a proceder ahora a guardar nuestro modelo en un fichero de disco duro denominado *model_checkpoint.pth*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'epoch': n_epochs,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': losses,\n",
    "              'val_loss': val_losses}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, si arrancamos de nuevo lo que necesitamos es cargar los códigos de preparación y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEamos que aquí el modelo no está entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que hacemos es cargar los datos que anteriormente hemos guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "saved_epoch = checkpoint['epoch']\n",
    "saved_losses = checkpoint['loss']\n",
    "saved_val_losses = checkpoint['val_loss']\n",
    "\n",
    "model.train() # always use TRAIN for resuming training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora cuales son los datos del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos obsrvar ahora el modelo si ha cargado adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando clases de Python para construir el modelo.\n",
    "\n",
    "En lo que sigue, vamos a utilizar la potencia de las clases de Python para integrar todo el código anterior en una clase y así hacer mucho más eficiente el código desarrollado hasta el momento.\n",
    "\n",
    "Comenzamos importando los módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comenzamos definiendo la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completely empty (and useless) class\n",
    "class StepByStep(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos la clase con el constructor de la misma (__init__). Construimos un método denominado *to* que servirá para enviar los objetos a la GPU si se dispone de la misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0        \n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step = self._make_train_step()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step = self._make_val_step()\n",
    "        \n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "            \n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "        \n",
    "    def _make_train_step_fn(self):\n",
    "        # This method does not need ARGS... it can refer to\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "\n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Sets model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "            loss.backward()\n",
    "            # Step 4 - Updates parameters using gradients and the\n",
    "            # learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "\n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "\n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Sets model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # There is no need to compute Steps 3 and 4, \n",
    "            # since we don't update parameters during evaluation\n",
    "            return loss.item()\n",
    "\n",
    "        return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final el código que queda es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # These attributes are defined here, but since they are\n",
    "        # not informed at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step_fn = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step_fn = self._make_val_step_fn()\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to define a SummaryWriter to interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # This method does not need ARGS... it can refer to\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "        \n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Sets model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "            loss.backward()\n",
    "            # Step 4 - Updates parameters using gradients and the learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "\n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Sets model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # There is no need to compute Steps 3 and 4, \n",
    "            # since we don't update parameters during evaluation\n",
    "            return loss.item()\n",
    "\n",
    "        return perform_val_step_fn\n",
    "            \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch can be used with both loaders\n",
    "        # The argument `validation`defines which loader and \n",
    "        # corresponding step function is going to be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn = self.train_step_fn\n",
    "\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "            \n",
    "        # Once the data loader and step function, this is the \n",
    "        # same mini-batch loop we had before\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "        loss = np.mean(mini_batch_losses)\n",
    "        return loss\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False    \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the numbers of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # inner loop\n",
    "            # Performs training using mini-batches\n",
    "            loss = self._mini_batch(validation=False)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            # VALIDATION\n",
    "            # no gradients in validation!\n",
    "            with torch.no_grad():\n",
    "                # Performs evaluation using mini-batches\n",
    "                val_loss = self._mini_batch(validation=True)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "            # If a SummaryWriter has been set...\n",
    "            if self.writer:\n",
    "                scalars = {'training': loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses for each epoch under the main tag \"loss\"\n",
    "                self.writer.add_scalars(main_tag='loss',\n",
    "                                        tag_scalar_dict=scalars,\n",
    "                                        global_step=epoch)\n",
    "\n",
    "        if self.writer:\n",
    "            # Closes the writer\n",
    "            self.writer.close()\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {'epoch': self.total_epochs,\n",
    "                      'model_state_dict': self.model.state_dict(),\n",
    "                      'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                      'loss': self.losses,\n",
    "                      'val_loss': self.val_losses}\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.losses = checkpoint['loss']\n",
    "        self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "        self.model.train() # always use TRAIN for resuming training   \n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set is to evaluation mode for predictions\n",
    "        self.model.eval() \n",
    "        # Takes aNumpy input and make it a float tensor\n",
    "        x_tensor = torch.as_tensor(x).float()\n",
    "        # Send input to device and uses model for prediction\n",
    "        y_hat_tensor = self.model(x_tensor.to(self.device))\n",
    "        # Set it back to train mode\n",
    "        self.model.train()\n",
    "        # Detaches it, brings it to CPU and back to Numpy\n",
    "        return y_hat_tensor.detach().cpu().numpy()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.losses, label='Training Loss', c='b')\n",
    "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def add_graph(self):\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        if self.train_loader and self.writer:\n",
    "            x_sample, y_sample = next(iter(self.train_loader))\n",
    "            self.writer.add_graph(self.model, x_sample.to(self.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos ahora a utilizar la clase anterior para poner en marcha nuestro proyecto. Comenzamos cargando los datos, lo hacemos con el programa Python siguiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "\n",
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1)\n",
    "y = true_b + true_w * x + (.1 * np.random.randn(N, 1))\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:int(N*.8)]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[int(N*.8):]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que lo ejecutamos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs data generation - so we do not need to copy code here\n",
    "%run -i data_generation/simple_linear_regression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a preparar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a la configuración del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_configuration/v4.py\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del código anterior obtenemos los objetos *model, loss function y optimizer* que vamos a pasar la clase creada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya entramos en el proceso de entrenar el modelo, con el uso de la clase *StepBuStep*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = StepByStep(model, loss_fn, optimizer)\n",
    "sbs.set_loaders(train_loader, val_loader)\n",
    "sbs.set_tensorboard('classy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbs.model == model)\n",
    "print(sbs.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos entrenar el modelo por ejemplo con epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.train(n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict()) # remember, model == sbs.model\n",
    "print(sbs.total_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También ahora podemos hacer previsiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([.5, .3, .7]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sbs.predict(new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una salvaguarda del modelo\n",
    "sbs.save_checkpoint('model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver a continuación, cómo cargariamos de nuevo el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sbs = StepByStep(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sbs.load_checkpoint('model_checkpoint.pth')\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen y después de todo el desarrollo anterior, con todo lo construido anteriormente, lo que se puede decir es que los pasos a dar para configurar estos modelos son:\n",
    "\n",
    "* Preparación de los datos (no generación de los mismos)\n",
    "\n",
    "* Configuración del modelo (función de pérdida, optimizador y modelo)\n",
    "\n",
    "* Entrenamiento del modelo (utilización de  de la clase StepByStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso.\n",
    "\n",
    "A continuación veamos un ejemplo de datos concretos donde aplicamos lo construido hasta ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# cargamos los datos\n",
    "df = pd.read_csv(\"datos/Pecan.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un modelo de regresión lineal simple, para ello seleccionamos las variables correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.values[:, 2].reshape(-1,1)\n",
    "y= df.values[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# escalamos los valores entre [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X=df.values[:, 2].reshape(-1,1)\n",
    "X=scaler.fit_transform(X)\n",
    "y= df.values[:,3].reshape(-1,1)\n",
    "y=scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hacemos la validación\n",
    "x_train, y_train = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.as_tensor(x_train).float()\n",
    "y_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "# (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = StepByStep(model, loss_fn, optimizer)\n",
    "sbs.set_loaders(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbs.model == model)\n",
    "print(sbs.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "sbs.train(n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict()) # remember, model == sbs.model\n",
    "print(sbs.total_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los parámetros estimados del modelo de regresión son muy similares a los que se han obtenido con estos mismos datos en el tema anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso regresión múltiple.\n",
    "\n",
    "Trabajaremos con la base de datos libre *Boston housing prices* de [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html).\n",
    "\n",
    "**DESCRIPCIÓN DE LAS VARIABLES DEL DATASET BOSTON HOUSING PRICES:**\n",
    "\n",
    "* CRIM: Per capita crime rate by town\n",
    "* ZN: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "* INDUS: Proportion of non-retail business acres per town\n",
    "* NOX: Nitric oxide concentration (parts per 10 million)\n",
    "* RM: Average number of rooms per dwelling\n",
    "* AGE: Proportion of owner-occupied units built prior to 1940\n",
    "* DIS: Weighted distances to five Boston employment centers\n",
    "* RAD: Index of accessibility to radial highways\n",
    "* TAX: full-value property-tax rate per \\$10,000\n",
    "* PTRATIO: Pupil-teacher ratio by town\n",
    "* B: $1000(B_k — 0.63)^2$, where Bk is the proportion of [people of African American descent] by town\n",
    "* LSTAT: Percentage of lower status of the population\n",
    "* MEDV: Median value of owner-occupied homes in \\$ $10^3$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "MEDV es la variable respuesta u objetivo de este problema de regresión  lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datos/Bostonraw.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = map(str.lower, df.columns) #convertimos las variables a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que no hay ningún valor faltante\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns   #seaborn es una extensión de matplotlib\n",
    "sns.set() \n",
    "# Estuiamos los outliers existentes\n",
    "for column in df:\n",
    "        plt.figure(figsize=(17,1))\n",
    "        sns.boxplot(data=df, x=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definción de la función que nos permitirá eliminar los outliers \n",
    "#para cada variable (columna)\n",
    "def eliminar_outlier(col): \n",
    "    sorted(col)\n",
    "    Q1,Q3=np.percentile(col,[25,75])\n",
    "    IQR=Q3-Q1\n",
    "    lowerthr= Q1-(1.5 * IQR) #UMBRAL INFERIOR\n",
    "    upperthr= Q3+(1.5 * IQR) #UMBRAL SUPERIOR\n",
    "    return lowerthr,upperthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns: #aplicamos la función eliminar_outlier para cada variable (columna) del dataframe\n",
    "    if df[column].dtype != 'object': \n",
    "        lowerthr,upperthr=eliminar_outlier(df[column])\n",
    "        df[column]=np.where(df[column]>upperthr,upperthr,df[column])\n",
    "        df[column]=np.where(df[column]<lowerthr,lowerthr,df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df:\n",
    "        plt.figure(figsize=(17,1))\n",
    "        sns.boxplot(data=df, x=column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización de los datos\n",
    "\n",
    "Hacemos un cambio de variable para que los datos tengan una media de cero y desviación típica de uno. Hacemos primero una copia de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfestand=df.copy()\n",
    "dfestand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #importamos la librería para estandarizar\n",
    "scalerX = StandardScaler()\n",
    "lista_columnas=['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'b', 'lstat']\n",
    "dfestand[lista_columnas] = scalerX.fit_transform(dfestand[lista_columnas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizamos la variable respuesta u objetivo (variable dependiente, **Y**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerY = StandardScaler()\n",
    "dfestand['medv']=scalerY.fit_transform(np.array(dfestand['medv']).reshape(len(dfestand['medv']),1)).reshape(len(dfestand['medv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las variables explicativas X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfestand.drop(['medv'],axis=1).values\n",
    "Y = dfestand['medv'].values\n",
    "Y = Y.reshape(-1,1)\n",
    "print(\"Dimensión de X:\",X.shape)\n",
    "print(\"Dimensión de Y\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasamos los datos anteriores a tensores\n",
    "x_tensor = torch.as_tensor(X).float()\n",
    "y_tensor = torch.as_tensor(Y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor,y_tensor)\n",
    "\n",
    "# Hacemos el split de los datos\n",
    "ratio = 0.8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total*ratio)\n",
    "n_val = n_total-n_train\n",
    "\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# creamos el DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuremos ahora el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de aprendizaje\n",
    "lr=0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# creamos el modelo\n",
    "par_entrada = X.shape[1] # es el número de variables predictoras\n",
    "model = nn.Sequential(nn.Linear(par_entrada, 1))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos definido los datos y la configuración del modelo, ahora procedemos a su entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = StepByStep(model, loss_fn, optimizer)\n",
    "sbs.set_loaders(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sbs.model == model)\n",
    "print(sbs.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.train(n_epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict()) # remember, model == sbs.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si queremos hacer predicciones, tenemos que pasar los datos de validación *val_dat* a un array numpy. Para obtener esto debemos ejecutar el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_val = val_data.dataset.tensors[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.predict(dat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora ya podemos obtener los indicadores de ajuste del modelo que deseemos (MAE,MSE, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndice.\n",
    "\n",
    "* <a href=\"https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/?utm_source=drip&utm_medium=email&utm_campaign=Text+Generation+with+LSTM+in+PyTorch&utm_content=Text+Generation+with+LSTM+in+PyTorch\" target=\"_blank\"> Un resumen de creación código PyTorch </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "197.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
