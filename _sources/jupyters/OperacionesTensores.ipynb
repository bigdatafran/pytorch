{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80afcef9",
   "metadata": {},
   "source": [
    "# operaciones con tensores.\n",
    "\n",
    "En este apartado vamos a contemplar ciertas operaciones con tensores de alto nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637797ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2770705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos tensores\n",
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3779c",
   "metadata": {},
   "source": [
    "Creamos un nuevo tensor para las operaciones de batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3872328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08d92f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la media en la dimensión -3 (channels)\n",
    "img_gray_naive = img_t.mean(-3)\n",
    "# Calculamos la media en la dimensión -3 (channels)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e1c2b",
   "metadata": {},
   "source": [
    "## Squeeze y unsqueeze.\n",
    "\n",
    "La operación de squeeze sirve para eliminar ciertas dimensiones de los tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b378e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "torch.squeeze(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbd89d",
   "metadata": {},
   "source": [
    "Con *unsqueeze* hacemos lo contrario. Así por ejemplo el tensor de pesos creado anteriormente, si le queremos añadir más dimensiones, lo haríamos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2897cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2126],\n",
       "        [0.7152],\n",
       "        [0.0722]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "322f73ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2126]],\n",
       "\n",
       "        [[0.7152]],\n",
       "\n",
       "        [[0.0722]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.unsqueeze(-1).unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea6533",
   "metadata": {},
   "source": [
    "## Tensores nombrados.\n",
    "\n",
    "```{index} Tensores nombrados\n",
    "```\n",
    "\n",
    "POdemos <a href=\"https://pytorch.org/tutorials/intermediate/named_tensor_tutorial.html\" target=\"_blank\"> nombrar a los tensores</a>, desde la versión 1.3 de PyTorch. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22c1fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\AppData\\Local\\Temp\\ipykernel_12476\\2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:848.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83d1ed",
   "metadata": {},
   "source": [
    "Cuando ya tenemos un tensor y queremos añadir nombres (pero no cambiar los existentes existentes), podemos llamar al método *refine_names*. De forma similar a la indexación, la elipsis (...) permite omitir cualquier número de dimensiones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833cc6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551aeeb",
   "metadata": {},
   "source": [
    "## Tipos de tensores.\n",
    "\n",
    "* torch.float32 or torch.float: 32-bit floating-point\n",
    "* torch.float64 or torch.double: 64-bit, double-precision floating-point\n",
    "* torch.float16 or torch.half: 16-bit, half-precision floating-point\n",
    "* torch.int8: signed 8-bit integers\n",
    "* torch.uint8: unsigned 8-bit integers\n",
    "* torch.int16 or torch.short: signed 16-bit integers\n",
    "* torch.int32 or torch.int: signed 32-bit integers\n",
    "* torch.int64 or torch.long: signed 64-bit integers\n",
    "* torch.bool: Boolean\n",
    "\n",
    "Veamos algunos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "351b509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb215305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6600e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f162281",
   "metadata": {},
   "source": [
    "## Almacenamiento de tensores.\n",
    "\n",
    "PyTorch almacena en memoria los números de forma consecutiva. Veamos un ejemplo sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ca7226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d6a23",
   "metadata": {},
   "source": [
    "El almacenamiento interno lo vemos con el método *storage()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8debe4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a2013e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatStorage'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = points.storage()\n",
    "print(type(a))\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908f0f3",
   "metadata": {},
   "source": [
    "### Stride.\n",
    "\n",
    "```{index} Stride\n",
    "```\n",
    "\n",
    "El **stride** es el número de elementos del almacenamiento que hay que saltar para obtener el siguiente elemento en cada dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "196babad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738d6bb",
   "metadata": {},
   "source": [
    "Que significa que para pasar de un elemento al siguiente en la primera dimensión hay que saltar 2 posiciones de almacenamiento, mientras que en la segunda dimensión sólo hay que saltar una posición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a3401",
   "metadata": {},
   "source": [
    "### Offset.\n",
    "\n",
    "```{index} storage offset\n",
    "```\n",
    "\n",
    "El storage offset es el índice en el almacenamiento correspondiente al primer elemento del tensor.\n",
    "\n",
    "Todos los elementos anteriores los podemos ver en el siguiente esquema\n",
    "\n",
    "![](figuras/ElementosTensor.PNG)\n",
    "\n",
    "Teniendo en cuenta todo lo anterior, en un tensor 2D para acceder al elemento (i,j), se haría mediante la siguiente fórmula:\n",
    "\n",
    "*storage_offsett +stride[0] * i+stride[1] * j*\n",
    "\n",
    "En la fórmula anterior hay que tener en cuenta que normalmente el valor del offsett es cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb554ba",
   "metadata": {},
   "source": [
    "## Transponiendo un tensor.\n",
    "\n",
    "Para trasponer un tensor se utiliza la función *t*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9142b59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07aedbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02984898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18204b8c",
   "metadata": {},
   "source": [
    "Esta transposición, no implica cambio en los posicionamientos de los números, como podemos ver con el código siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89816e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3037b10c",
   "metadata": {},
   "source": [
    "Pero los stride's sí que cambian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0c9509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1f90f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7b0e2",
   "metadata": {},
   "source": [
    "Para comprender mejor el significado de los valores obtenidos con stride(), nos apoyaremos en el siguiente esquema.\n",
    "\n",
    "![](figuras/stride_transpose.PNG)\n",
    "\n",
    "En dimensiones superiores, por ejemplo tres, los resultados que obtenemos los podemos ver en el siguiente ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c7765cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1792040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7a7b4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51ca77e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bea2c",
   "metadata": {},
   "source": [
    "## Moviendo tensores a GPU\n",
    "\n",
    "Los tensores en PyTorch pueden estar almacenados tanto en la CPU del ordenador como en la GPU. Por defecto, un tensor queda almacenado en la CPU, pero existe el método *device* para indicar dónde se quiere crear. A continuación veamos cómo lo creamos en la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de2b5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36f954",
   "metadata": {},
   "source": [
    "Si un tensor lo tenemos creado en la CPU, pero lo queremos pasar a la GPU, lo haremos de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a80c268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bd577",
   "metadata": {},
   "source": [
    "Para poder ver si un tensor lo tenemos almacenado en GPU o en CPU, podemos utilizar la propiedad *is_cuda*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc57703e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b46936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3918d8e",
   "metadata": {},
   "source": [
    "## Intercambio con Numpy.\n",
    "\n",
    "PyTorch tiene una buena relación de intercambio con el paquete numpy. En el siguiente ejemplo, creamos un tensor y lo pasamos a un numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eee8dfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a65a0",
   "metadata": {},
   "source": [
    "De forma reciproca, se puede pasar de un numpy array a un tensor de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59651aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.from_numpy(points_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a94b21",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "Crear un tensor desde una lista de tamaño 9. Calcular con él el tamaño, offset y stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6eafe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([1,2,3,4,5,6,7,8,9])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4bac3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26d1c430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0367873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2243f",
   "metadata": {},
   "source": [
    "Crear un nuevo tensor b=a.view(3,3). la propiedad *view* sirve para hacer un reshape del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a1446ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.view(3,3)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6001bf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ae34d",
   "metadata": {},
   "source": [
    "Crear un tenssor c=b[1:,1:].Predecir y chequear el tamaño, offset y stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6387558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a801a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [8., 9.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b[1:,1:]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca255f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de15682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddb258",
   "metadata": {},
   "source": [
    "Aplicar la función sqrt de torch al tensor a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "156ead5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4142, 1.7321, 2.0000, 2.2361, 2.4495, 2.6458, 2.8284, 3.0000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfca0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
